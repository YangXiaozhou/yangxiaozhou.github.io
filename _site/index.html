<!DOCTYPE html>
<html lang="en-us">

<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
  <!-- include collecttags -->
  
  





  

  <title>
    
      Xiaozhou's Notes &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link href="https://fonts.googleapis.com/css?family=East+Sea+Dokdo&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.0/css/all.min.css" rel="stylesheet">




  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- MathJax -->
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  // Autonumbering by mathjax
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-89141653-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-89141653-4');
</script>



  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <!-- <a href="/"> -->
          Xiaozhou's Notes
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      <!-- Manual set order -->
      <a class="sidebar-nav-item" href="/categories">Categories</a>
      <a class="sidebar-nav-item" href="/publication">Publication</a>
      <a class="sidebar-nav-item" href="/about">About</a>

      <!-- Uncomment for auto order -->
      <!-- 

      
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/categories/">Categories</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/publication/">Publication</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
       -->

      
      <!-- <a class="sidebar-nav-item" href="https://github.com/yangxiaozhou/yangxiaozhou.github.io">GitHub project</a> -->
      <!-- <span class="sidebar-nav-item">Currently v</span> -->
      
<div id="social-media">
    
    
        
        
            <a href="mailto:xiaozhou.yang@u.nus.edu" title="Email"><i class="fa fa-envelope"></i></a>
        
    
        
        
            <a href="https://www.linkedin.com/in/yangxiaozhou" title="Linkedin"><i class="fab fa-linkedin"></i></a>
        
    
        
        
            <a href="https://github.com/YangXiaozhou" title="GitHub"><i class="fab fa-github"></i></a>
        
    
        
        
            <a href="https://www.youtube.com/user/a315345751" title="YouTube"><i class="fab fa-youtube"></i></a>
        
    
</div>


    </nav>

    <p>&copy; 2020. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h2 class="post-title">
      <a href="/journal/2020/06/06/journal-2020-05.html">
        2020å¹´5æœˆï¼šæµ…å°Snack Writing
      </a>
    </h2>

    <span class="post-date">06 Jun 2020</span>

    <p>äº”æœˆå› ä¸ºç–«æƒ…çš„åŸå› ç»§ç»­åœ¨å®¶é‡Œå·¥ä½œã€‚è¿™æ®µæ—¶é—´å·¥ä½œé‡å¿ƒä¸»è¦åœ¨å†™ä¸œè¥¿ä¸Šé¢ï¼Œä¸å¤ªéœ€è¦è·‘å¤§é‡çš„æ•°æ®ã€ä¹Ÿä¸éœ€è¦å¤ªå¤šè·ŸåŒäº‹è€æ¿çš„äº¤æµï¼Œè™½ç„¶æˆ‘è›®æƒ³å¿µåŠå…¬å®¤çš„espressoå’–å•¡å’Œæ—¶ä¸æ—¶ä¸åŒé¢†åŸŸçš„äººè¿‡æ¥åšçš„seminarçš„ï¼Œè¿™ä¸¤ä»¶äº‹å„¿å®¶é‡Œæ²¡æ³•å¤åˆ¶ã€‚</p>

    <!-- <p>äº”æœˆå› ä¸ºç–«æƒ…çš„åŸå› ç»§ç»­åœ¨å®¶é‡Œå·¥ä½œã€‚è¿™æ®µæ—¶é—´å·¥ä½œé‡å¿ƒä¸»è¦åœ¨å†™ä¸œè¥¿ä¸Šé¢ï¼Œä¸å¤ªéœ€è¦è·‘å¤§é‡çš„æ•°æ®ã€ä¹Ÿä¸éœ€è¦å¤ªå¤šè·ŸåŒäº‹è€æ¿çš„äº¤æµï¼Œè™½ç„¶æˆ‘è›®æƒ³å¿µåŠå…¬å®¤çš„espressoå’–å•¡å’Œæ—¶ä¸æ—¶ä¸åŒé¢†åŸŸçš„äººè¿‡æ¥åšçš„seminarçš„ï¼Œè¿™ä¸¤ä»¶äº‹å„¿å®¶é‡Œæ²¡æ³•å¤åˆ¶ã€‚</p>

<p>æäº¤äº†ä¸Šä¸€ç¯‡æ–‡ç« çš„å®¡ç¨¿æ„è§å›å¤ï¼Œä¸¤ä¸ªå®¡ç¨¿äººæäº†ä¸å°‘é—®é¢˜ä½†éƒ½æ˜¯å»ºè®¾æ€§æˆ–è€…æ¾„æ¸…ç±»çš„ï¼Œæˆ‘å†™çš„å›å¤åˆç¨¿è¢«è€æ¿ä¿®æ”¹ä¸å°‘ï¼ˆFirst version is always subpar.)ã€‚æˆ‘å‘ç°æˆ‘çš„å›å¤å¾€å¾€æ›´å©‰è½¬ã€è¿‚å›ï¼Œç”¨è¯ä¹Ÿä¹ æƒ¯æ€§åœ°ç”¨æˆ‘ç†Ÿæ‚‰çš„è¿™ä¸ªå·¥ä½œçš„è¯­è¨€ï¼›è€Œå¯¹æ¯”è€æ¿ä¿®æ”¹è¿‡çš„ç‰ˆæœ¬ï¼Œè¡¨è¾¾çš„ç‚¹æ˜¯ä¸€æ ·çš„ï¼Œä½†è¿™ä¸ªç‚¹åœ¨ä»–çš„å›å¤é‡Œå°±å¾ˆæ˜ç¡®ã€æ›´assertiveï¼ŒåŒæ—¶ä¹ŸæŠŠé‚£äº›æ›´æŠ€æœ¯æ€§çš„è¯è¯­æ¢æˆäº†æ›´æ˜“ç†è§£çš„ã€‚è¿™ä¹ˆä¸€æƒ³ï¼Œæ¯æ¬¡åšæŠ¥å‘Šçš„é—®ç­”ç¯èŠ‚æˆ‘ä¹Ÿæ˜¯è¿™æ ·ã€‚æœ€åæäº¤ä¸Šå»çš„å›å¤ï¼Œç»™æˆ‘çš„æ„Ÿè§‰æ˜¯ï¼šåŒæ„çš„ç‚¹ä¼šæ˜ç¡®è¯´ã€ä¸æ¸…æ¥šçš„ç‚¹ä¼šç”¨æµ…æ˜¾çš„è¯­è¨€è§£é‡Šã€è¯¯è§£äº†çš„ç‚¹ä¼šç”¨ä¸å‘ä¸äº¢çš„å§¿æ€æ¾„æ¸…ã€‚æœ€åæ ¹æ®å®¡ç¨¿äººæ„è§åšè¿‡ä¿®æ”¹çš„æ–‡ç« ï¼Œç¡®å®æ˜¯è¦æ¯”ä¹‹å‰çš„ç‰ˆæœ¬æ›´å®Œæ•´ã€å¯èƒ½é€ æˆè¯¯è§£çš„åœ°æ–¹æ›´å°‘äº†ã€‚</p>

<p>ä¸‹åŠæœˆæŠŠä¹‹å‰å¥½ä¸å®¹æ˜“ææ‡‚çš„æ–¹æ³•ç”¨$\LaTeX$ä¸€ä¸€æ‰“å‡ºæ¥å†™è¿›äº†è‡ªå·±çš„ç¬”è®°é‡Œï¼Œç„¶ååˆåŸºäºè¿™ä¸ªç¬”è®°å†™äº†ç¬¬äºŒä¸ªå·¥ä½œçš„æ–‡ç« çš„åˆç¨¿ï¼ˆä¸»è¦æ˜¯æ–¹æ³•éƒ¨åˆ†ï¼‰ï¼ŒåŒ…æ‹¬ç”µåŠ›ç³»ç»Ÿçš„åŠ¨æ€æ¨¡å‹ã€ç”¨particle filteråšçŠ¶æ€ä¼°è®¡ä»¥åŠå¦‚ä½•ç”¨EMåšå‚æ•°ä¼°è®¡ã€‚æ–¹æ³•é‡Œé¢è‡ªå·±èŠ±æ—¶é—´æœ€ä¹…çš„åº”è¯¥æ˜¯æœ€åé‚£ä¸ªå‚æ•°ä¼°è®¡çš„æ–¹æ³•ï¼Œä¸Šä¸€ç¯‡æœˆå¿—ä¹Ÿæåˆ°è¿‡ï¼Œåœ¨ç¬”è®°é‡Œçš„ç¯‡å¹…ä¹Ÿæ˜¯æœ€é•¿çš„ï¼Œå› ä¸ºå„ç§æ­¥éª¤ã€‚ä¸è¿‡ï¼Œå› ä¸ºä¸æ˜¯è¿™ä¸ªå·¥ä½œçš„é‡ç‚¹ï¼Œæœ€ç»ˆå†™åˆ°æ–‡ç« é‡Œå°±åªæœ‰å‡ æ®µè¯ã€‚è¿™é“ç†ï¼Œåšä¸€çš„æ—¶å€™<a href="https://www.eng.nus.edu.sg/isem/staff/ye-zhisheng/">å¶è€å¸ˆ</a>è¯¾ä¸Šå°±å·²ç»è·Ÿæˆ‘ä»¬åˆ†äº«è¿‡äº†ï¼Œå†™æ–‡ç« çš„æ—¶å€™è¦</p>
<blockquote>
  <p>Write around your contributions, not about what you have learnt.</p>
</blockquote>

<p>è¿™ä¸€æ¬¡å†™ï¼Œå°è¯•äº†ä¸€ä¸ªæ–°çš„å†™ä½œæ¨¡å¼ï¼šæ¯å¤©æ—©ä¸Šèµ·åºŠåå†™ä¸€ä¸ªå°æ—¶ä»»ä½•æˆ‘ç°åœ¨åœ¨å†™çš„ã€åœ¨å­¦çš„ä¸œè¥¿ã€‚ç¼˜ç”±æ˜¯æˆ‘å›å»å†è¯»äº†ä¸€ä¸‹ä¸Šä¸ªæ—¥å¿—è¯´åˆ°çš„é‚£æœ¬ä¹¦ï¼Œé‡Œé¢æœ‰ä¸“é—¨å†™åˆ°ç ”ç©¶ç”Ÿåº”è¯¥å¦‚ä½•å†™ä½œã€‚è¿™é‡Œçš„â€œå¦‚ä½•å†™ä½œâ€ä¸æ˜¯æŒ‡çš„å†™ä½œé£æ ¼ã€è¯­è¨€ç»„ç»‡ä¹‹ç±»ï¼Œè€Œæ˜¯æŒ‡ä»€ä¹ˆæ—¶å€™å†™ï¼Œå†™äº›ä»€ä¹ˆã€‚ä¹¦ä¸­ä¸»è¦æåˆ°</p>
<ol>
  <li>Donâ€™t write when ready, write to be ready.</li>
  <li>Donâ€™t be binge writing, be snack writing.</li>
  <li>Schedule regular sessions for writing.</li>
  <li>Writing means writing, not editing.</li>
</ol>

<p>ç¡®å®æ˜¯è¿™æ ·ã€‚æˆ‘ç»å¸¸è§‰å¾—å¾—ç­‰æˆ‘æ‰€æœ‰æ–¹æ³•éƒ½å®Œå…¨ææ‡‚äº†ï¼Œæ¯ä¸€ä¸ªç»†èŠ‚éƒ½èµ°é€šäº†ï¼Œæ‰èƒ½åŠ¨æ‰‹å¼€å§‹å†™ï¼›è€Œä¸”å› ä¸ºç»å¸¸æ˜¯åœ¨çŸ­æ—¶é—´å†…å†™å¤§é‡çš„å†…å®¹ï¼Œå†™å®Œæ€»ä¼šæ„Ÿè§‰å¾ˆç´¯ï¼›æœ‰çš„æ—¶å€™ä¹Ÿä¼šå‘ç°èŠ±äº†æ—¶é—´å´åªå†™äº†å‡ å¥è¯ï¼ŒåŸæ¥æ˜¯æ—¶é—´éƒ½ç”¨å»åšç¼–è¾‘$\LaTeX$ç¬¦å·ã€æ’å…¥æ–‡çŒ®è¿™ç§äº‹äº†ã€‚</p>

<p>æ‰€ä»¥æˆ‘ç»™è‡ªå·±å®šäº†ä¸ªæ–°çš„å†™ä½œæ¨¡å¼ï¼šæ—©ä¸Šèµ·åºŠåä¸“æ³¨å†™ä¸€å°æ—¶çš„å†…å®¹ï¼Œå†…å®¹æ˜¯æ¥ç€æ˜¨å¤©å†™çš„ï¼Œå¹¶ä¸”åªæœ‰å†™ä½œï¼›ç™½å¤©çš„æ—¶å€™å†æ¥æ…¢æ…¢ä¿®æ”¹å­—ç¬¦ï¼Œæ·»åŠ æ–‡çŒ®å’Œæ£€æŸ¥é”™åˆ«å­—ä¹‹ç±»çš„ç¼–è¾‘å·¥ä½œã€‚è¿™æ ·çš„æ¨¡å¼å†™äº†å¤§åŠæœˆï¼Œå‘ç°å†™ä½œè¿›åº¦ç¡®å®å¾ˆå¿«ï¼ˆç›¸å¯¹ä»¥å‰ï¼‰ï¼Œä¸€ç‚¹ä¸€ç‚¹æŠŠä¹‹å‰å¤§å¤šåªæ˜¯åœç•™åœ¨è‰ç¨¿æœ¬å’Œä»£ç ä¸Šçš„å·¥ä½œéƒ½ç³»ç»Ÿåœ°å†™è¿›äº†ç¬”è®°ï¼Œç„¶ååˆæ ¹æ®ç¬”è®°å†™äº†æ–‡ç« çš„åˆç¨¿ï¼Œåœ¨å†™çš„è¿‡ç¨‹ä¸­ä¹ŸæŠŠå¾ˆå¤šç»†èŠ‚çš„ä¸œè¥¿æ‹æ¸…äº†ä¸å°‘ã€‚ä¸è¿‡ï¼Œæˆ‘è§‰å¾—ç”¨è¿™æ ·çš„å†™ä½œæ¨¡å¼æœ‰ä¸€ä¸ªè¦æ±‚ï¼Œé‚£å°±æ˜¯å¾—æå‰æ‰“å¥½è‰ç¨¿ï¼šå…·ä½“å†…å®¹ã€æçº²ã€æ¯ä¸€éƒ¨åˆ†çš„æ ¸å¿ƒå†…å®¹ç­‰è‡ªå·±å¾—çŸ¥é“ï¼Œä¸ç„¶çš„è¯ï¼Œæ—©ä¸Šä¸€å°æ—¶å¾ˆéš¾å†™å‡ºä¸œè¥¿ï¼Œå³ä½¿å†™å‡ºæ¥äº†ï¼Œå¤§éƒ¨åˆ†å†…å®¹æˆ‘åæ¥éƒ½æƒ³æ”¹æ‰é‡å†™ã€‚</p>

<p>ä¸ºä»€ä¹ˆè¦æŠŠå­¦è¿‡çš„ä¸œè¥¿åƒä¹¦ä¸€æ ·å†™è¿›ç¬”è®°é‡Œå‘¢ï¼Ÿå› ä¸ºå‰é¢å†™åˆ°çš„å†™ä½œæ¨¡å¼å’Œéœ€è¦å†™æ–‡ç« çš„åŸå› ï¼Œå¼€å§‹å¯»æ€ç€èƒ½ä¸èƒ½æŠŠèŠ±æ—¶é—´ææ‡‚çš„ä¸œè¥¿ä»¥ç³»ç»Ÿçš„ã€æˆ‘è‡ªå·±èƒ½æ˜ç™½çš„æ–¹å¼å†™è¿›ç¬”è®°ï¼Ÿå½“ç„¶å¯ä»¥ï¼Œä½†é—®é¢˜æ˜¯ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Ÿæ¯•ç«Ÿå­¦æœ¯æ–‡ç« æ‰€éœ€çš„å†…å®¹å’Œè¡Œæ–‡é£æ ¼è·Ÿç¬”è®°è¿˜æ˜¯å¾ˆä¸ä¸€æ ·çš„ï¼Œè¿™å°±æ„å‘³ç€æ›´å¤šçš„å†™ä½œå·¥ä½œé‡ï¼Œ$\LaTeX$å†™èµ·æ¥ä¹Ÿæ²¡é‚£ä¹ˆè½»æ¾ã€‚å…¶å®è¿™äº‹å„¿å‰ä¸¤å¹´ä¹Ÿæƒ³è¿‡ï¼Œä¸»è¦è¿˜æ˜¯æƒ³å»ºç«‹ä¸€ä¸ªå±äºè‡ªå·±çš„çŸ¥è¯†ä½“ç³»å¹¶èƒ½ä¸æ–­ä¿®æ”¹å’Œæ‰©å……å®ƒå§ã€‚</p>

<p>å‰æ®µæ—¶é—´å› ä¸ºå†™â€œ<a href="https://yangxiaozhou.github.io/data/2020/05/17/francis-galton.html">Francis Galton: ç»´å¤šåˆ©äºšæ—¶ä»£çš„åšå­¦å®¶ä¸ä»–è§‚å¯Ÿåˆ°çš„å¥‡å¦™ä¸–ç•Œ</a>â€ï¼Œåœ¨è±†ç“£æœç´¢å…³äºGaltonçš„æ–‡ç« ï¼Œè¯»åˆ°äº†äºæ·¼çš„åšå®¢ï¼Œèµ·åˆæƒŠå¹äºä»–çš„ç¬”è§¦é—´æ¸—é€ç€ç”Ÿç‰©ã€æ•°å­¦ã€ç»Ÿè®¡å’Œç¼–ç¨‹ç­‰æ–¹é¢å¤šå¹´ç§¯ç´¯çš„çŸ¥è¯†ä»¥åŠå¯¹äºç§‘ç ”å’Œè¿™ä¸ªä¸–ç•Œçš„ä¸€äº›ç‹¬åˆ°çš„è§è§£ã€‚äº†è§£ä¹‹åæ‰å‘ç°è¿™ä½æ¥è‡ªä¸­ç§‘é™¢çš„åšå£«åœ¨ç¯å¢ƒç§‘å­¦æ–¹é¢åšç ”ç©¶ï¼Œ16å¹´ä»ä¸­ç§‘é™¢æ¯•ä¸šçš„ä»–ç®—æ˜¯è¶…å“¥ï¼ˆæˆ‘çš„co-authorï¼‰å°ä¸‰å±Šçš„å¸ˆå¼Ÿã€‚ä»æ—¶é—´çº¿ä¸Šçœ‹å¾—åˆ°ï¼Œè¯»åšä»¥æ¥è¿™ä¹ˆå¤šå¹´ï¼Œä¸€ç›´æœ‰åœ¨åšå®¢ä¸Šå†™è®¨è®ºå„ç§é—®é¢˜çš„åšæ–‡ï¼Œå¤§å¤šæ˜¯åŸºäºè§‚å¯Ÿã€å­¦ä¹ ä¸ç ”ç©¶çš„è®®é¢˜ã€‚åŒæ—¶è¿™ä½å“¥ä»¬çƒ­è¡·äºä¸Šç½‘è¯¾è¯»æ•™æï¼Œæ›´çˆ±åšç¬”è®°æ•´ç†çŸ¥è¯†ï¼Œç›®å‰ä»–çš„åšå®¢ä¸Šæœ‰è¿™ä¹ˆå¤šå¹´ç§¯æ”’ä¸‹æ¥çš„çŸ¥è¯†ç¬”è®°çš„<a href="http://yufree.github.io/notes/index.html">æ±‡ç¼–</a>ï¼Œæœ€åæˆ‘å‘ç°ï¼Œä»–è¿˜æ˜¯ç»Ÿè®¡ä¹‹éƒ½çš„ç¼–è¾‘éƒ¨ä¸»ç¼–ã€‚å‰å®³ï¼</p>

<p>å¤§æ¦‚å°±æ˜¯æƒ³å°è¯•åšè¿™ä¸ªäº‹å„¿å§ï¼Œä¸€ä¸ªä¸€ä¸ªå¯¹å­¦è¿‡çš„ä¸œè¥¿åšç³»ç»Ÿæ€§çš„æ•´ç†ï¼Œæ¢³ç†æ¡†æ¶ç„¶åå†™æˆç›¸å¯¹å®Œæ•´çš„ç¬”è®°ï¼Œå¯¹æ¡†æ¶é‡Œçš„æ¯ä¸ªéƒ¨åˆ†é€æ¸å½¢æˆè‡ªå·±çš„ç†è§£ï¼›åœ¨ä¹‹åçš„æ‰©å……è¿‡ç¨‹ä¸­æ—¢èƒ½æ‰¾åˆ°æ–°çŸ¥è¯†åœ¨æ¡†æ¶ä¸­çš„ä½ç½®ï¼Œä¹Ÿèƒ½ä¸æ–­æ›´æ–°è‡ªå·±çš„æ¡†æ¶å’Œç†è§£ã€‚</p>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/reading/2020/06/01/reading-guns-germs-steels.html">
        æªç‚®ã€ç—…èŒä¸é’¢é“
      </a>
    </h2>

    <span class="post-date">01 Jun 2020</span>

    <p>[History: Science or art?]</p>

    <!-- <p>[History: Science or art?]</p>
 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/05/17/francis-galton.html">
        Francis Galton: ç»´å¤šåˆ©äºšæ—¶ä»£çš„åšå­¦å®¶ä¸ä»–è§‚å¯Ÿåˆ°çš„å¥‡å¦™ä¸–ç•Œ
      </a>
    </h2>

    <span class="post-date">17 May 2020</span>

    <p>å‘¨æœ«è¯»Aeonçš„ä¸€ç¯‡æ–‡ç« ï¼š<a href="https://aeon.co/ideas/algorithms-associating-appearance-and-criminality-have-a-dark-past?utm_source=Aeon+Newsletter&amp;utm_campaign=f7c118f081-EMAIL_CAMPAIGN_2020_05_11_01_52&amp;utm_medium=email&amp;utm_term=0_411a82e59d-f7c118f081-69607277">Algorithms associating appearance and criminality have a dark past</a>ï¼Œè®²ç°åœ¨æœ‰ç ”ç©¶äººå‘˜ç”¨æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡äººè„¸æ¥åˆ¤æ–­æŸäººçŠ¯ç½ªçš„å‡ ç‡ã€‚æ–‡ä¸­è®²åˆ°è¿™ç§ä»äººå¤–è¡¨æå–é¢„è§æ€§ç‰¹å¾çš„å°è¯•ï¼Œåœ¨çŠ¯ç½ªå­¦å†å²ä¸Šå¹¶ä¸æ–°å¥‡ï¼Œ19ä¸–çºªçš„æ„å¤§åˆ©çŠ¯ç½ªå­¦å®¶Cesare Lombrosoè®¤ä¸ºç½ªçŠ¯çš„è„¸éƒ¨æœ‰ç‹¬ç‰¹çš„æ ·è²Œï¼šçªå‡ºçš„å‰é¢ã€é¹°å‹é¼»æ¢ï¼›è€Œ18ä¸–çºªçš„Francis Galtonåˆ™å°è¯•å›ç­”ä¸€ä¸ªæ›´å¹¿æ³›çš„é—®é¢˜ï¼šäººçš„å¤–è¡¨è·Ÿä»–æˆ–å¥¹çš„å¥åº·çŠ¶å†µã€çŠ¯ç½ªå€¾å‘ã€æ™ºåŠ›ç­‰ç­‰æœ‰å…³ç³»å—ï¼Ÿæˆ–è€…è¯´ï¼Œäººçš„åŸºå› æ˜¯å¦å†³å®šäº†å¥åº·ã€è¡Œä¸ºã€æ™ºåŠ›å’Œç«äº‰åŠ›ï¼Ÿ</p>

    <!-- <p>å‘¨æœ«è¯»Aeonçš„ä¸€ç¯‡æ–‡ç« ï¼š<a href="https://aeon.co/ideas/algorithms-associating-appearance-and-criminality-have-a-dark-past?utm_source=Aeon+Newsletter&amp;utm_campaign=f7c118f081-EMAIL_CAMPAIGN_2020_05_11_01_52&amp;utm_medium=email&amp;utm_term=0_411a82e59d-f7c118f081-69607277">Algorithms associating appearance and criminality have a dark past</a>ï¼Œè®²ç°åœ¨æœ‰ç ”ç©¶äººå‘˜ç”¨æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡äººè„¸æ¥åˆ¤æ–­æŸäººçŠ¯ç½ªçš„å‡ ç‡ã€‚æ–‡ä¸­è®²åˆ°è¿™ç§ä»äººå¤–è¡¨æå–é¢„è§æ€§ç‰¹å¾çš„å°è¯•ï¼Œåœ¨çŠ¯ç½ªå­¦å†å²ä¸Šå¹¶ä¸æ–°å¥‡ï¼Œ19ä¸–çºªçš„æ„å¤§åˆ©çŠ¯ç½ªå­¦å®¶Cesare Lombrosoè®¤ä¸ºç½ªçŠ¯çš„è„¸éƒ¨æœ‰ç‹¬ç‰¹çš„æ ·è²Œï¼šçªå‡ºçš„å‰é¢ã€é¹°å‹é¼»æ¢ï¼›è€Œ18ä¸–çºªçš„Francis Galtonåˆ™å°è¯•å›ç­”ä¸€ä¸ªæ›´å¹¿æ³›çš„é—®é¢˜ï¼šäººçš„å¤–è¡¨è·Ÿä»–æˆ–å¥¹çš„å¥åº·çŠ¶å†µã€çŠ¯ç½ªå€¾å‘ã€æ™ºåŠ›ç­‰ç­‰æœ‰å…³ç³»å—ï¼Ÿæˆ–è€…è¯´ï¼Œäººçš„åŸºå› æ˜¯å¦å†³å®šäº†å¥åº·ã€è¡Œä¸ºã€æ™ºåŠ›å’Œç«äº‰åŠ›ï¼Ÿ</p>

<h3 id="francis-galtonæ˜¯è°">Francis Galtonæ˜¯è°ï¼Ÿ</h3>
<p>è¿™åå­—çœ‹èµ·æ¥æœ‰ç‚¹çœ¼ç†Ÿï¼Œæˆ‘éšçº¦è®°å¾—åœ¨è€æ¿çš„ä¸€é—¨Forecastingç»Ÿè®¡è¯¾ä¸Šå¬åˆ°è¿‡ã€‚ä»”ç»†ä¸€æƒ³ï¼Œå¯¹ï¼Œåœ¨çº¿æ€§å›å½’çš„éƒ¨åˆ†ï¼Œè€æ¿ä¸Šè¯¾ä¸“é—¨ä»‹ç»äº†ä»–ã€‚Sir Francis Galtonï¼Œå§“Galtonï¼ŒåFrancisï¼Œä½†å½“æåˆ°ä»–æ—¶ï¼Œå‡ºäºç¤¼ä»ªï¼Œä½ å¾—åŠ ä¸ªSirï¼Œå› ä¸ºä»–åœ¨1909å¹´è¢«è‹±å›½å¥³ç‹æˆäºˆäº†éª‘å£«çˆµä½ã€‚ä¸ºä»€ä¹ˆåœ¨è®²çº¿æ€§å›å½’çš„æ—¶å€™è¦ä»‹ç»ä»–å‘¢ï¼Ÿå› ä¸ºä»–ä½œä¸ºç¬¬ä¸€ä¸ªäººï¼Œè§‚å¯Ÿå¹¶è®°å½•äº†è¿™æ ·ä¸€ç§ç°è±¡<sup id="fnref:Galton_heights"><a href="#fn:Galton_heights" class="footnote">1</a></sup>ï¼šå¹³å‡èº«é«˜å¾ˆé«˜çš„çˆ¶æ¯ï¼Œå¾€å¾€ä¼šæœ‰èº«é«˜æ›´æ¥è¿‘æ™®é€šçš„å­©å­ï¼›è€Œå¹³å‡èº«é«˜åä½çš„çˆ¶æ¯çš„å­©å­ï¼Œæˆå¹´åé€šå¸¸æœ‰ç€æ›´æ¥è¿‘æ™®é€šäººçš„èº«é«˜ã€‚
ä¸‹å›¾æ˜¯<a href="https://www.ams.org/journals/bull/2013-50-01/S0273-0979-2012-01374-5/S0273-0979-2012-01374-5.pdf">Bradley Efron</a>æ ¹æ®Galtonå½“æ—¶æ”¶é›†åˆ°çš„çˆ¶æ¯å’Œå­©å­çš„èº«é«˜æ•°æ®é‡æ–°åˆ¶çš„å›¾ï¼Œå®Œç¾åœ°å±•ç°äº†æˆ‘ä»¬ç°åœ¨æ‰€çŸ¥é“çš„Bivariate normal distributionã€‚
<img src="/assets/francis-galton/regression_to_mean.png" alt="regression_to_mean" /></p>

<p>ä»–æŠŠè¿™ç§ç°è±¡ç§°ä¸º<a href="https://www.jstor.org/stable/2841583">regression towards mediocrity</a>ï¼Œç°åœ¨é€šå¸¸å«åšregression toward the meanï¼Œä¸­æ–‡è²Œä¼¼å«â€œå‘å‡æ•°å›å½’â€ã€‚åŒæ ·çš„ç°è±¡ï¼Œæˆ‘ä»¬åœ¨ç”Ÿæ´»ä¸­å¾ˆå¤šåœ°æ–¹éƒ½èƒ½è§‚å¯Ÿåˆ°ï¼šå› ä¸ºè¿æ°”è€ŒæŠ¼ä¸­é¢˜ç›®çš„å­¦ç”Ÿè€ƒå‡ºäº†é«˜åˆ†ï¼Œä¸‹ä¸€æ¬¡è€ƒè¯•çš„æˆç»©å´æ²¡é‚£ä¹ˆçªå‡ºï¼›è¿ç»­æŠ•ä¸­ä¸‰ä¸ªä¸‰åˆ†çƒçš„æœ‹å‹ï¼Œä¸‹ä¸ªçƒå¾€å¾€â€œå®¹æ˜“â€å¤±æ‰‹ï¼›æˆ‘ä¸Šå‘¨åš<a href="https://yangxiaozhou.github.io/learning/2019/01/01/recipe.html#%E6%B2%B9%E6%B3%BC%E7%8C%AA%E6%89%8B">æ²¹æ³¼çŒªæ‰‹</a>æ—¶å„ç§è°ƒæ–™æ‹¿æå¾—å¾ˆå¥½ï¼Œå‘³é“è¶…æ£’ï¼Œè¿™å‘¨å†åšä¸€æ¬¡ï¼Œå¤§æ¦‚ç‡å‘³é“ä¼šæ¯”è¾ƒæ™®é€šğŸ¤·â€â™‚ï¸ã€‚</p>

<p>ç¬¦åˆè¿™åŸåˆ™çš„ç°è±¡ï¼Œä»–ä»¬æœ‰ä¸€ä¸ªå…±é€šç‚¹ï¼šä»–ä»¬çš„ç»“æœå¾€å¾€å®Œå…¨æˆ–éƒ¨åˆ†ç”±éšæœºå› ç´ å†³å®šï¼Œè€Œéšæœºå› ç´ çš„å½±å“å¾€å¾€ç¬¦åˆä»¥0ä¸ºä¸­å¿ƒçš„æ­£æ€åˆ†å¸ƒï¼ˆæ—¶å¥½æ—¶åï¼‰ã€‚æ¯”å¦‚è¯´ï¼Œä¸‰åˆ†çƒè¿›æˆ–ä¸è¿›ï¼Œæœ‰æŠ•æ‰‹èƒ½åŠ›çš„å½±å“ä½†ä¹Ÿæœ‰è¿æ°”çš„æˆåˆ†ï¼›æˆ‘åšçš„æŸé“èœçš„å‘³é“ï¼Œå–å†³äºä¸‹å¨èƒ½åŠ›ï¼Œä½†æˆ‘çš„ä¸“å¿ƒç¨‹åº¦ã€æ‰‹æŠ–ç¨‹åº¦ä»¥åŠå¿ƒæƒ…ç­‰å‡ ä¹éšæœºçš„å› ç´ ä¹Ÿä¼šæœ‰æ‰€å½±å“ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå‡è®¾æŸä¸€å¤©æˆ‘è¶…çº§èµ°è¿ï¼Œåšå‡ºäº†è¿„ä»Šä¸ºæ­¢æœ€å¥½åƒçš„ä¸€é“èœï¼Œè¿™ç§äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡æ˜¯å¾ˆå°çš„ï¼ˆå¾—åˆ°æ­£æ€åˆ†å¸ƒä¸Šçš„æå¤§å€¼æˆ–æå°å€¼çš„æ¦‚ç‡ï¼‰ã€‚ä¸‹ä¸€æ¬¡åšï¼Œå¤§æ¦‚ç‡æˆ‘ä¼šæ­£å¸¸å‘æŒ¥ï¼Œèœçš„å‘³é“ä¹Ÿæ²¡ä¸Šæ¬¡å¥½ï¼ˆå–åˆ°äº†æ­£æ€åˆ†å¸ƒä¸Š0å‘¨å›´çš„æŸä¸ªå€¼ï¼‰ã€‚</p>

<p>æƒ³è±¡è¿™æ ·ä¸€ç§æƒ…å†µï¼šæœ‹å‹åœ¨æˆ‘æ¬æ–°å®¶çš„æ—¶å€™æ¥å®¶é‡Œåƒé¥­ï¼Œåˆšå¥½ç¢°åˆ°æˆ‘å‰é¢è¯´çš„è¶…å¸¸å‘æŒ¥ï¼Œéƒ½è¯´åšçš„çŒªæ‰‹å¥½åƒï¼è¿‡äº†å‡ ä¸ªæœˆï¼Œå®¶é‡Œèšä¼šï¼Œåº”æœ‹å‹å¼ºçƒˆè¦æ±‚ï¼Œå†æ¬¡åšå‡ºä¸€ç›˜çŒªæ‰‹ï¼Œä¸è¿‡è¿™æ¬¡æ˜¯æ­£å¸¸å‘æŒ¥ã€‚æœ‹å‹åƒåå›å¿†èµ·ä¹‹å‰ï¼Œè¯„è®ºåˆ°ï¼šâ€œæ°´å¹³ä¸‹é™äº†å‘€ï¼â€ æˆ‘å†¤ä¸å†¤ï¼Ÿ è¿™æ ·çš„å†¤æ‰æˆ‘ä»¬ç”Ÿæ´»ä¸­è¿˜çœŸä¸å°‘ï¼Œä»¥è‡³äºå®ƒæœ‰ä¸ªä¸“é—¨çš„ç§°å‘¼ï¼šRegression fallacyï¼Œä¸­æ–‡å«â€œå›å½’è°¬è¯¯â€ã€‚Daniel Kahnemanè®²è¿‡äº²èº«ç»å†çš„è¿™æ ·<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3292229/">ä¸€ä¸ªä¾‹å­</a>ï¼šä»–æœ‰ä¸€æ¬¡ç»™é£è¡Œå‘˜å­¦æ ¡åšåŸ¹è®­ï¼Œæåˆ°äº†è¡¨æ‰¬èƒ½ä½¿å­¦å‘˜å˜å¾—æ›´ä¼˜ç§€ã€‚ä¸‹é¢çš„ä¸€ä¸ªæ•™å®˜ä¸åŒæ„äº†ï¼Œè¯´ä»–æ¯æ¬¡ä¸€å¤¸å®Œé™è½åšå¾—ç®€ç›´å®Œç¾çš„å­¦å‘˜ï¼Œä¸‹ä¸€æ¬¡ä¸€å®šåšå¾—æ²¡é‚£ä¹ˆå¥½ï¼Œè€Œåˆšè¢«ä»–éª‚è¿‡çš„å­¦å‘˜ï¼Œé©¬ä¸Šå°±èƒ½çœ‹åˆ°æå‡ã€‚å¬äº†æ•™å®˜çš„æŠ—è®®ï¼ŒKahnemanå½“ä¸‹æœ‰äº†ä¸€ä¸ªeureka momentï¼Œä»–è¯´é“ï¼š</p>
<blockquote>
  <p>because we tend to reward others when they do well and punish them when they do badly, and because there is regression to the mean, it is part of the human condition that we are statistically punished for rewarding others and rewarded for punishing them.</p>
</blockquote>

<p>å›å½’è°¬è¯¯å¯ä»¥ç”¨æ•°å­¦è¯æ˜ï¼Œå‡è®¾ä¸¤ä¸ªå˜é‡ä»¥bivariate normal distributionåˆ†å¸ƒï¼Œåªè¦ä»–ä»¬çš„correlationå°äº1ï¼Œå°±ä¼šæœ‰å›å½’è°¬è¯¯å‡ºç°ï¼Œå¯¹è¯æ˜æ„Ÿå…´è¶£çš„æœ‹å‹å¯ä»¥çœ‹<a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean">ç»´åŸº</a>ã€‚</p>

<h3 id="å¹´åº¦å…¬ç‰›ä½“é‡ç«çŒœ">å¹´åº¦å…¬ç‰›ä½“é‡ç«çŒœ</h3>
<p>è®©æˆ‘ä»¬å›åˆ°è§‚å¯Ÿå°å¤©æ‰Galtonã€‚1907å¹´ä¸‰æœˆçš„è‡ªç„¶æ‚å¿—ä¸ŠåˆŠç™»äº†ä»–ä¸€ç¯‡ç¯‡å¹…åªæœ‰ä¸€é¡µçš„<a href="https://www.nature.com/articles/075450a0">æ¥ä¿¡</a>ï¼Œåä¸ºï¼šVox Populiï¼Œç›´è¯‘ä¸ºâ€œæ°‘ä¼—çš„å£°éŸ³â€ï¼Œç°åœ¨æŒ‡å¤§å¤šæ•°äººçš„æ„è§ã€‚ä½åœ¨è‹±å›½Plymouthçš„ä»–ï¼Œæ³¨æ„åˆ°äº†å®¶é™„è¿‘çš„é•‡å­ä¸Šæ¯å¹´éƒ½æœ‰ä¸¾åŠè¿™æ ·ä¸€ç§å®¶ç¦½ä½“é‡ç«çŒœæ´»åŠ¨ï¼šä¸»åŠæ–¹æ‹‰ä¸€å¤´ç‰›å‡ºæ¥ï¼Œå‚ä¸ç«çŒœçš„æœ¬åœ°å†œå¤«ã€å± å¤«ç­‰æ„Ÿå…´è¶£ä¸”æœ‰ç»éªŒè€…å¯¹ç‰›è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å°†ä»–è®¤ä¸ºè¿™å¤´ç‰›è¢«å®°æ€æ´—å‡€ä¹‹åçš„ä½“é‡æäº¤ä¸Šå»ã€‚æœ¬ç€å¯¹å¤§ä¼—æ™ºæ…§çš„ç§‘å­¦ç ”ç©¶æ€åº¦ï¼Œä»–é€šè¿‡æŸç§æ–¹å¼è·å¾—äº†ä¸€æ¬¡ç«çŒœæ¯”èµ›ä¸­çš„æ•°æ®ï¼šç‰›çš„çœŸå®ä½“é‡ä»¥åŠ787ä¸ªç«çŒœè€…çš„ä¼°è®¡ã€‚</p>

<p style="display: block; margin-left: auto; margin-right: auto; width: 100%;"><img src="/assets/francis-galton/stock_show.jpg" alt="stock_show" /></p>

<p>ä»–æŠŠæäº¤çš„æ‰€æœ‰ç«çŒœä½“é‡ä»å°åˆ°å¤§æ’åˆ—å¼€ï¼Œå‘ç°ä¸­ä½æ•°ï¼ˆä¸€åŠçš„æ•°æ¯”å®ƒä½ï¼Œä¸€åŠæ¯”å®ƒé«˜ï¼Œâ€medianâ€ä¸€è¯å°±æ˜¯ä»–ç»™å–çš„ï¼‰æ˜¯1207ç£…ï¼Œè€Œé‚£å¤´ç‰›çš„çœŸå®å‡€ä½“é‡æ˜¯1198ç£…ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ°‘ä¼—çš„åˆ¤æ–­åœ¨è¿™é‡Œè·ŸçœŸå®å€¼åªå·®äº†0.8%ï¼<sup id="fnref:correction"><a href="#fn:correction" class="footnote">2</a></sup>
åœ¨é‚£ä¸ªçº¿æ€§å›å½’è¿˜ä¸æ˜¯æ‰€æœ‰æ•°æ®åˆ†æè¯¾ç¨‹çš„ç¬¬ä¸€èŠ‚è¯¾ï¼Œæ•°æ®ç§‘å­¦ä¹Ÿè¿˜ä¸æ˜¯ä¸€ç§èŒä¸šçš„æ—¶å€™ï¼ŒGaltonä»787ä¸ªç«çŒœä½“é‡ä¸­é€šè¿‡ç®€å•çš„æ‰‹ç®—çœ‹åˆ°äº†ä»¥å¹³å‡å€¼æˆ–ä¸­ä½æ•°å¯¹çœŸå®å€¼è¿›è¡Œä¼°è®¡çš„å‡†ç¡®æ€§ã€‚ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†ï¼Œsample mean is an unbiased estimator of the true population meanã€‚</p>

<p>Galtonçš„è§‚å¯Ÿæ²¡æœ‰åœåœ¨ä¼°è®¡çš„å‡†ç¡®æ€§ä¸Šï¼Œä»–è¿˜æƒ³çŸ¥é“ï¼Œæ¯ä¸ªäººä¼°è®¡çš„è¯¯å·®æœ‰å¤šå¤§ã€‚ä»–éšå³æŠŠæ‰€æœ‰ä¼°è®¡ä¸ä¸­ä½æ•°çš„åå·®ç”»äº†å‡ºæ¥ï¼Œä»–å‘ç°ï¼Œæ¯ä¸€ä¸ªæœ‰ç»éªŒçš„â€œè‚‰çœ¼æµ‹ä½“é‡è€…â€æ‰€åšçš„ä¼°è®¡ï¼Œä»ä½ä¼°çš„åˆ°é«˜ä¼°çš„ï¼Œä¸€ç³»åˆ—çš„åå·®ä¸æ­£æ€åˆ†å¸ƒæä¸ºç›¸ä¼¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœæŠŠçœŸå®å‡€ä½“é‡çœ‹åšæ˜¯è¿™ä¸ªé‡‡æ ·åˆ†å¸ƒçš„meanï¼Œé‚£ä»»æ„ä¸€ä¸ªå‚èµ›è€…ï¼ˆæœ‰ç»éªŒçš„ï¼‰æ¥ä¼°è®¡ï¼Œä»–çš„ä¼°è®¡å€¼å°†æ˜¯ä»¥çœŸå®å‡€ä½“é‡ä¸ºä¸­å¿ƒçš„æ­£æ€åˆ†å¸ƒè€Œåˆ†å¸ƒç€çš„ï¼ˆç»•å£ï¼ï¼‰ã€‚Letâ€™s try again. The estimate by any pair of trained eyes is distributed normally around the true dressed weight of the ox. è¿™é‡Œæˆ‘ä»¬å¾—æä¸€ä¸ªæ— æ•°ç°ä»£ç§‘å­¦ä¾èµ–çš„ç†è®ºï¼šCentral limit theorem (CLT)ã€‚å¯¹ï¼Œå°±æ˜¯é‚£ä¸ªå¯ä»¥è§£é‡Šä¸ºä»€ä¹ˆæ­£æ€åˆ†å¸ƒåœ¨ç°å®ç”Ÿæ´»ä¸­å¦‚æ­¤æ™®éçš„ç†è®ºã€‚å› ä¸ºCLTï¼Œæˆ‘ä»¬ç°åœ¨ç¡®åˆ‡åœ°çŸ¥é“ï¼Œå½“æ ·æœ¬é‡è¶³å¤Ÿå¤§æ—¶ï¼Œæ ·æœ¬å¹³å‡å€¼å‘ˆä»¥çœŸå®å€¼ä¸ºä¸­å¿ƒçš„æ­£æ€åˆ†å¸ƒã€‚æ‰€ä»¥ï¼Œä»å¹´åº¦å…¬ç‰›ä½“é‡ç«çŒœçš„çœŸå®æ•°æ®ä¸Šï¼Œä»–ï¼ŒSir Francis Galtonï¼Œçœ‹åˆ°äº†central limit theoremã€‚</p>

<p>é™„ä¸Šä»–åŸç¨¿é‡Œçš„è·Ÿç†è®ºæ­£æ€åˆ†å¸ƒåšå¯¹æ¯”çš„å›¾ï¼Œæ¨ªè½´æ˜¯ç™¾åˆ†ä½ï¼Œçºµè½´æ˜¯åå·®ï¼š
<img src="/assets/francis-galton/francis-galton-the-wisdom-of-crowds.jpg" alt="francis-galton-the-wisdom-of-crowds" /></p>

<h3 id="galton-boardä¸æŸé’å“¥">Galton Boardä¸æŸé’å“¥</h3>
<p>Galtonå¯¹äºè¿™ç§æ²¡æœ‰å¾å…†ä½†åˆè¿‘ä¹å®šå¾‹èˆ¬å‘ˆæ­£æ€åˆ†å¸ƒçš„åå·®éå¸¸ç€è¿·ï¼Œä»–æŠŠåå·®å‘ˆç°å‡ºæ¥çš„å›¾ç§°ä¸º:The Curve of Frenquencyï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ç°åœ¨ç†ŸçŸ¥çš„æ ·æœ¬åå·®çš„æ­£æ€åˆ†å¸ƒå›¾ã€‚ä¸ºäº†å±•ç°è¿™ç§åå·®çš„æ­£æ€åˆ†å¸ƒï¼ˆå³ï¼ŒCLT)ä»¥åŠå‰é¢æåˆ°çš„å›å½’è°¬è¯¯ï¼ŒGaltonè®¾è®¡äº†ä¸€ä¸ªä»¤äººæ‹æ¡ˆå«ç»çš„è£…ç½®ï¼šGalton Boardï¼Œç°åœ¨ä¹Ÿå«bean machineï¼Œå¦‚ä¸‹å›¾ï¼š</p>

<p style="display: block; margin-left: auto; margin-right: auto; width: 75%;"><img src="/assets/francis-galton/GaltonBoard.png" alt="GaltonBoard" /></p>

<p>åƒä¸åƒæˆ‘ä»¬å°æ—¶å€™åœ¨è¡—å··çš„å°å–éƒ¨é‡Œç©è¿‡çš„å¼¹ç æœºï¼Ÿæ²¡é”™ï¼Œä»–ä»¬çš„èƒŒåæ˜¯åŒæ ·çš„åŸç†ã€‚å®é™…ä¸Šï¼Œé£é¡å…¨æ—¥æœ¬çš„æŸé’å“¥ä¹Ÿæ˜¯ç”¨çš„è¿™æ ·çš„è®¾è®¡åŸç†ï¼šå¼¹ç ä»é¡¶éƒ¨è½ä¸‹ï¼Œç»è¿‡è·Ÿè‹¥å¹²å±‚çš„æ’é’ˆçš„æ’å‡»ï¼Œæœ€ç»ˆæ‰è¿›æœ€ä¸‹é¢ä»å·¦åˆ°å³Nä¸ªæ¡¶å½“ä¸­çš„æŸä¸ªæ¡¶é‡Œã€‚å› ä¸ºæˆ‘ä»¬å¹¶ä¸çŸ¥é“å¼¹ç åœ¨è·Ÿæ¯ä¸€æ ¹æ’é’ˆæ’å‡»ä¹‹åæ˜¯èµ°å·¦è¿˜æ˜¯èµ°å³ï¼Œæ‰€ä»¥æŸä¸ªå¼¹ç çš„æœ€ç»ˆä½ç½®å¹¶ä¸èƒ½æå‰çŸ¥é“ï¼ˆi.e. éšæœºäº‹ä»¶ï¼Œéšæœºæ¼«æ­¥ï¼Œéšæœºè¿‡ç¨‹ï¼‰ã€‚</p>

<p>ä½†ï¼è™½ç„¶å•ç‹¬ä¸€ä¸ªå¼¹ç çš„å»å‘æ— æ³•æå‰è·çŸ¥ï¼Œä½†æˆ‘ä»¬å´æœ‰åŠæ³•çŸ¥é“æŸä¸ªå¼¹ç è½å…¥æŸä¸ªåŒºé—´çš„æ¦‚ç‡ã€‚ç²—ç•¥æ¥è¯´ï¼Œå¼¹ç åˆ°è¾¾æŸä¸€ä¸ªæ¡¶çš„è·¯çº¿æ•°é‡é™¤ä»¥æ‰€æœ‰å®ƒå¯èƒ½èµ°çš„è·¯çº¿ï¼Œå°±æ˜¯å®ƒè¿›å…¥æŸä¸ªæ¡¶çš„æ¦‚ç‡ã€‚æ¯”å¦‚ï¼Œä¸€é¢—å¼¹ç æƒ³è¦åˆ°è¾¾æœ€å·¦è¾¹çš„åŒºé—´ï¼Œå®ƒåªæœ‰ä¸€æ¡è·¯å¯ä»¥èµ°ï¼šä»ç¬¬ä¸€å±‚å¼€å§‹ä¸€ç›´å¾€å·¦å¼¹ã€‚ç®—å‡ºå…¶ä»–åŒºé—´çš„è·¯çº¿æ•°å’Œæ¦‚ç‡å¯ä»¥æœ‰å¾ˆå¤šæ–¹æ³•ï¼Œæ¯”å¦‚æšä¸¾ï¼ˆè´¹åŠ²ï¼‰æˆ–ç”¨æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½ ä¹Ÿå¾ˆèƒ½è§‚å¯Ÿï¼ï¼‰ï¼Œä¹Ÿå¯ä»¥æ ¹æ®Binomial distributionçš„probability mass function (pmf)å¾—åˆ°ï¼ˆ$n$æ˜¯æ’é’ˆçš„å±‚æ•°ï¼Œ$k$æ˜¯æ¡¶çš„ç¼–å·ï¼Œ$p$æ˜¯å¼¹ç æ’å‡»åå¼¹å·¦çš„æ¦‚ç‡ï¼‰ï¼š</p>

<script type="math/tex; mode=display">\operatorname{Pr}(X=k)=\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k}</script>

<p>for $k = 0, \dots, n$.</p>

<p>è¯»åˆ°è¿™é‡Œï¼Œäº†è§£CLTçš„æœ‹å‹æˆ–è®¸å·²ç»æ˜ç™½ä¸ºä»€ä¹ˆè¿™ä¸ªGalton boardå¯ä»¥å±•ç¤ºå‘ˆæ­£æ€åˆ†å¸ƒçš„åå·®äº†ã€‚CLTçš„ä¸€ä¸ªç‰¹æ®Šåº”ç”¨æ˜¯è¯æ˜å½“è¯•éªŒçš„æ¬¡æ•°($n$)è¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œbinomial distributionçš„pmfä¼šè·Ÿæ­£æ€åˆ†å¸ƒååˆ†ç›¸ä¼¼ã€‚æ¢å¥è¯è¯´ï¼Œå½“æˆ‘ä»¬çš„Galton boardè¶³å¤Ÿå¤§ï¼ŒåŒæ—¶æ‰”ä¸‹çš„å¼¹ç è¶³å¤Ÿå¤šçš„æ—¶å€™ï¼Œæˆ‘ä»¬åº”è¯¥å°±èƒ½çœ‹åˆ°ç»å…¸çš„æ­£æ€åˆ†å¸ƒBell curveï¼Genius!</p>

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/jiWt77xme64" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></center>

<hr />
<p>ä¸ºä»€ä¹ˆæˆ‘ä»¬è¯´è¿™ä¸ªå¼¹ç æœºä¹Ÿèƒ½å±•ç¤ºä¹‹å‰æåˆ°çš„å›å½’è°¬è¯¯å‘¢ï¼Ÿé¦–å…ˆï¼Œè®©æˆ‘ä»¬æŠŠåˆšæ‰é‚£å‡ ç™¾ä¸ªå¼¹ç è½ä¸‹æ¥ä¹‹åå‘ˆç°å‡ºæ¥çš„åˆ†å¸ƒè®°åœ¨è„‘æµ·ä¸­ã€‚è®©æˆ‘å†æ¬¡ä½¿ç”¨åšèœçš„ä¾‹å­ï¼Œå‡è®¾è½åˆ°æœ€å³ç«¯çš„å¼¹ç ä»£è¡¨ç€æˆ‘åšå‡ºäº†è¿„ä»Šä¸ºæ­¢æœ€å¥½åƒçš„ä¸€é“èœï¼Œå› ä¸ºä¸å¯»å¸¸åœ°èµ°è¿ï¼ˆå¼¹ç æ‰å…¥æœ€å³è¾¹çš„å‡ ç‡éå¸¸å°ï¼‰ã€‚ç°åœ¨ï¼Œæˆ‘æŠŠè¿™é¢—å¼¹ç æ‹¿å‡ºæ¥ï¼Œè®©å®ƒä»é¡¶éƒ¨å†ä¸€æ¬¡ä¸‹è½ï¼ˆå†åšä¸€æ¬¡åŒæ ·çš„èœï¼‰ï¼Œä½ è§‰å¾—å¤§æ¦‚ç‡ä¼šæ˜¯æ‰åœ¨å“ªç‰‡åœ°æ–¹ï¼Ÿæœ‰å¤šå¤§æ¦‚ç‡å†æ¬¡åˆ°è¾¾æœ€å³ç«¯ï¼ˆåšå‡ºåŒæ ·é«˜æ°´å¹³çš„èœï¼‰ï¼Ÿ</p>

<p>å‘µï¼ŒLife!</p>

<p>å¯¹äºä¼—å¤šå¼¹ç çœ‹ä¼¼éšæœºã€æ— æ³•é¢„æµ‹åœ°è½ä¸‹ï¼Œæœ€åè¢«æŸç§é­”åŠ›èšæ‹¢ï¼Œä¸€ä¸ªæŒ¨ç€ä¸€ä¸ªï¼Œé€æ¸å‘ˆç°å‡ºç¾ä¸½çš„æ­£æ€åˆ†å¸ƒçš„ç°è±¡ï¼ŒGaltonè‡ªå·±æ˜¯è¿™æ ·æè¿°çš„ï¼š</p>
<blockquote>
  <p>Order in Apparent Chaos: I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by the Law of Frequency of Error. The law would have been personified by the Greeks and deified, if they had known of it. It reigns with serenity and in complete self-effacement amidst the wildest confusion. The huger the mob, and the greater the apparent anarchy, the more perfect is its sway. It is the supreme law of Unreason. Whenever a large sample of chaotic elements are taken in hand and marshalled in the order of their magnitude, an unsuspected and most beautiful form of regularity proves to have been latent all along.</p>
</blockquote>

<h3 id="ç»“è¯­">ç»“è¯­</h3>
<p>Francis Galtonä½œä¸ºè‹±å›½ç»´å¤šåˆ©äºšæ—¶æœŸçš„ä¸€ä½åšå­¦å®¶ï¼Œç»å†å®åœ¨æ˜¯å¤ªè¿‡ä¸°å¯Œã€‚è‡ªå¹¼å‡ºç”Ÿåœ¨å¯Œè¶³ç²¾è‹±çš„å®¶åº­ï¼Œä»–æ˜¯è¾¾å°”æ–‡çš„è¡¨å¼Ÿï¼Œå¹´è½»æ—¶ç»§æ‰¿äº†çˆ¶äº²çš„å¤§ç¬”é—äº§ä¹‹åå»éæ´²å¤§é™†æ¢é™©ï¼Œå›å›½ä¹‹åå†™æˆçš„æ¸¸è®°æˆäº†ç•…é”€ä¹¦ã€‚ç”¨ä»–æ•é”çš„è§‚å¯ŸåŠ›å’Œå¥½å¥‡å¿ƒï¼ŒGaltonç ”ç©¶äº†å¾ˆå¤šé—®é¢˜ï¼Œæœ‰äº›æ²¡å•¥å®é™…å½±å“ï¼ˆæœ€ä½³åˆ‡è›‹ç³•æ³•ã€æœ€ä½³æ²èŒ¶æ³•ï¼‰ï¼Œæœ‰äº›å´æ”¹å˜äº†ä¼—å¤šé¢†åŸŸæ¥ä¸‹æ¥ä¸€ç™¾å¤šå¹´çš„å‘å±•ã€‚ä»–åšäº†æ—©æœŸçš„å›å½’åˆ†æã€æå‡ºäº†correlationçš„æ¦‚å¿µã€å°†ç»Ÿè®¡åº”ç”¨åˆ°é—ä¼ å­¦ã€å¿ƒç†å­¦ï¼Œæ•°ç†ç»Ÿè®¡æœ€é‡è¦çš„å­¦è€…ä¹‹ä¸€Karl Pearsonæ˜¯ä»–çš„å­¦ç”Ÿã€‚åŒæ—¶ï¼Œä»–ä¸ºäº†å¾—åˆ°æ•°æ®ï¼Œå‘æ˜äº†é—®å·è°ƒæŸ¥ï¼›ç ”ç©¶å¤©æ°”ï¼Œå‘æ˜äº†ç¬¬ä¸€å¼ å¤©æ°”åœ°å›¾ã€å¼€å¯äº†å¯¹æ°”å€™çš„ç§‘å­¦ç ”ç©¶ï¼›æå‡ºäº†ä¸€ç§æœ‰æ•ˆè¯†åˆ«æŒ‡çº¹çš„æ–¹æ³•ï¼Œå¯¹å½“æ—¶çš„æ³•åŒ»å­¦åšäº†æ¨åŠ¨ã€‚å“¦ï¼Œå¯¹äº†ï¼Œæ­£å¦‚æˆ‘ä»¬å¼€å¤´æ‰€è¯´ï¼Œä»–ä¹Ÿæå‡ºäº†ä¸€ç§æ ¹æ®ä¸åŒäººè„¸å›¾åƒæå–â€œå¹³å‡ç‰¹å¾â€çš„æ–¹æ³•ã€‚</p>

<p>Galtonæ‰€è§‚å¯Ÿåˆ°çš„ä¸–ç•Œï¼Œè®©ä»–æœ‰äº†å¾ˆå¤šç–‘é—®ï¼Œä»–å°è¯•ç”¨å„ç§æ–¹æ³•å»ä¸ˆé‡è¿™ä¸ªä¸–ç•Œï¼Œå¹¶ä»çœ‹ä¼¼æ··æ²Œæ— åºçš„ç°è±¡ä¸­æ‰¾åˆ°ç§©åºå’Œè§„å¾‹ã€‚æˆ‘æƒŠå¹äºGaltonçš„è§‚å¯ŸåŠ›ã€è·Ÿéšè‡ªå·±å¥½å¥‡å¿ƒä¸æ–­çš„æ¢ç´¢ä¸å°è¯•ä»¥åŠå¯¹è‡ªå·±ä¸“ä¸šä¸è®¾é™çš„æ€åº¦ã€‚æ–‡è‰ºå¤å…´äººçš„ç²¾ç¥åŠ²å„¿å¯è§ä¸€æ–‘ã€‚å¥½äº†ï¼Œä¸å¤šè¯´äº†ï¼Œæˆ‘è¦å»å…¥æ‰‹ä¸€ä¸ªGalton boardäº†ã€‚</p>

<p>æœ€åé™„ä¸Šä¸€ä¸ªæŠŠGalton boardè§£é‡Šå¾—æ¯”æˆ‘æ¸…æ¥šå¾—å¤šã€è¯™è°åˆå¹½é»˜çš„å“¥ä»¬çš„<a href="https://www.youtube.com/embed/UCmPmkHqHXk">è§†é¢‘</a>ã€‚</p>

<h3 id="æ³¨é‡Š">æ³¨é‡Š</h3>

<div class="footnotes">
  <ol>
    <li id="fn:Galton_heights">
      <p>è¿™é‡Œæ”¾ä¸ŠGaltonè‡ªå·±åˆ¶ä½œçš„çˆ¶æ¯å­©å­èº«é«˜å›å½’å›¾ï¼š<img src="/assets/francis-galton/Galton's_correlation_diagram_1875.jpg" alt="Galton_heights" />Â <a href="#fnref:Galton_heights" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:correction">
      <p>åæ¥çš„ç ”ç©¶ä¿®æ­£äº†GaltonåŸç¨¿çš„æ•°æ®é”™è¯¯ï¼Œå½“æ—¶é‚£å¤´ç‰›çš„çœŸå®å‡€ä½“é‡åº”è¯¥æ˜¯1197ï¼Œè€Œä¸­ä½æ•°ä¼°è®¡åº”è¯¥æ˜¯1208ã€‚åœ¨åŸç¨¿ä¸­ï¼ŒGaltonç”¨ä¸­ä½æ•°è¿›è¡Œäº†çœŸå®å€¼ä¼°è®¡ã€‚ä¸è¿‡ï¼Œå½“æ—¶787ä¸ªä¼°è®¡çš„å¹³å‡æ•°æ˜¯1197ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¹³å‡æ•°å…¶å®ä»¥é›¶è¯¯å·®çš„è¡¨ç°ä¼°è®¡åˆ°äº†çœŸå®å€¼ï¼Â <a href="#fnref:correction" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/journal/2020/04/30/journal-2020-04.html">
        2020å¹´4æœˆï¼šæ›´éš¾çš„æ–¹æ³•ä¸æœ‰å¥—è·¯çš„äº¤æµ
      </a>
    </h2>

    <span class="post-date">30 Apr 2020</span>

    <p>è¿™ä¸ªæœˆæ”¶åˆ°äº†ç¨¿å­çš„æ¶ˆæ¯ï¼Œåœ¨å°è¯•æ‹¼ä¸Šæœ€åä¸€å—é—®é¢˜çš„â€œæ‹¼å›¾â€ï¼Œä»¥åŠæ€è€ƒå¦‚ä½•åä¸Šå¸æœºçš„ä½ç½®ã€‚</p>

    <!-- <p>è¿™ä¸ªæœˆæ”¶åˆ°äº†ç¨¿å­çš„æ¶ˆæ¯ï¼Œåœ¨å°è¯•æ‹¼ä¸Šæœ€åä¸€å—é—®é¢˜çš„â€œæ‹¼å›¾â€ï¼Œä»¥åŠæ€è€ƒå¦‚ä½•åä¸Šå¸æœºçš„ä½ç½®ã€‚</p>

<p>ä¸€è½¬çœ¼åˆä¸¤ä¸ªæ˜ŸæœŸæ²¡è·Ÿè€æ¿ï¼ˆåšå£«å¯¼å¸ˆï¼‰è®¨è®ºç ”ç©¶ä¸Šçš„é—®é¢˜äº†ã€‚</p>

<p>ä¸Šå‘¨èŠè¿‡å…³äºå›å¤å®¡ç¨¿äººæ„è§çš„äº‹ï¼Œç¬¬ä¸€æ¬¡æŠ•ç¨¿å’Œæ”¶åˆ°ä¿®æ”¹æ„è§ï¼Œå¤šå°‘æœ‰ç‚¹å¿å¿‘ã€‚å­¦æœ¯æ–‡ç« å‘è¡¨çš„è¿‡ç¨‹å¤§è‡´æ˜¯æŠ•ç¨¿ã€ç¼–è¾‘æŠ„é€ç»™åŒ¿åå®¡ç¨¿äººã€å®¡ç¨¿äººå›å¤ï¼ˆæ¨èä¸å¦åŠ ä¸Šå…·ä½“æ„è§ï¼‰ã€ç¼–è¾‘å›å¤ï¼ˆæ¥å—ã€ä¿®æ”¹ã€æ‹’ç»ï¼‰ã€‚å¦‚æœå›å¤æ˜¯ä¿®æ”¹ï¼Œé‚£å¯èƒ½ä¼šé‡å¤å‡ è½®è¿™ä¸ªæ­¥éª¤ã€‚å¯èƒ½æ˜¯å› ä¸ºç–«æƒ…çš„å…³ç³»ï¼Œå»å¹´åä¸€æœˆå°±æŠ•å‡ºå»çš„æ–‡ç« ï¼Œå†æ—¶äº”ä¸ªæœˆï¼Œä¸Šä¸Šå‘¨æ‰æ”¶åˆ°å›å¤ï¼Œå¹¶ä¸”åªæœ‰ä¸¤ä¸ªå®¡ç¨¿äººã€‚æˆ‘æ‰“å¿ƒé‡Œæ„Ÿè°¢è¿™ä¸¤ä½å®¡ç¨¿äººåœ¨è¿™ç‰¹æ®Šæ—¶æœŸè¿˜å®¡æˆ‘çš„ç¨¿ï¼Œå¹¶ä¸”æçš„å¤§å¤šæ˜¯å¯»æ±‚è¿›ä¸€æ­¥è§£é‡Šæˆ–è€…è®ºè¿°æ€§è´¨çš„æ„è§ï¼Œè€Œä¸æ˜¯â€œè´¨ç–‘â€å‹çš„é—®é¢˜ã€‚</p>

<p>æ¯å‘¨å‘¨äºŒï¼Œæ˜¯æˆ‘ä»¬å¾€å¸¸ç»„ä¼šå’Œè§é¢è®¨è®ºçš„æ—¥å­ã€‚è‡ªä»ç–«æƒ…åœ¨æ–°åŠ å¡æ‰©æ•£ä»¥æ¥ï¼Œå­¦æ ¡å…ˆæ˜¯è§„å®šä¼šè®®è¦æµ‹ä½“æ¸©ç™»è®°æ—¶é—´ç­‰ç­‰ï¼Œä¸ä¹…å°±è¦æ±‚å…¨å‘˜åœ¨å®¶å·¥ä½œäº†ã€‚å…¨æ ¡äººå‘˜æ’¤ç¦»æ ¡å›­çš„åŒæ—¶ï¼Œæ‰€æœ‰è·Ÿæ–°å† ç—…æ¯’ç›¸å…³çš„ç ”ç©¶æ´»åŠ¨å¾—åˆ°ç‰¹æ®Šå…è®¸ï¼Œå¯ä»¥ç»§ç»­å¼€å±•ã€‚æˆ‘ä»¬è¿™ä¸€ç±»ä¸ç”¨åšå®éªŒæœ‰ç”µè„‘å°±èƒ½å·¥ä½œçš„ç ”ç©¶ï¼Œåœ¨å®¶å·¥ä½œæ²¡å¤ªå¤§å½±å“ï¼›Scienceã€åœŸæœ¨ä¸€ç±»éœ€è¦å­¦æ ¡èµ„æºåšå®éªŒçš„æœ‹å‹ä»¬å°±æ²¡é‚£ä¹ˆå¹¸è¿äº†ï¼Œä¸çŸ¥é“ä»–ä»¬ç°åœ¨åœ¨å®¶é‡Œå¦‚ä½•ç»§ç»­ç§‘ç ”ï¼Œåˆšå¥½é›†ä¸­ç²¾åŠ›æ•´ç†æ•°æ®å†™å†™æ–‡ç« ï¼Ÿ</p>

<p>ä¸çŸ¥é“æ˜¯å¦æ˜¯å‡ºäºä¹ æƒ¯ï¼Œå‘¨äºŒä¸€ä¸Šç­å°±æŠŠæœ€è¿‘å›°æ‰°æˆ‘çš„é—®é¢˜å¥½å¥½ç»„ç»‡æ‰“ç¨¿ä¸€ç•ªå‘ç»™äº†è€æ¿ã€‚è¿™é—®é¢˜ç®—æ˜¯æˆ‘ç›®å‰å·¥ä½œçš„æœ€åä¸€å—â€œæ‹¼å›¾â€å§ã€‚ç²—ç•¥æ¥è¯´ï¼Œæˆ‘æ¨¡å‹é‡Œæœ‰ä¸ªæœªçŸ¥çš„å‚æ•°è¦ä¼°è®¡ï¼Œä½†é—®é¢˜æ˜¯çº¿ä¸‹ï¼ˆoffline)è¿˜æ˜¯çº¿ä¸Š(online)ä¼°è®¡ã€‚çº¿ä¸‹ä¼°è®¡éœ€è¦ä¸€å®šæ•°é‡çš„è®­ç»ƒæ•°æ®ï¼Œä¹Ÿå¾ˆéš¾ä¿è¯æ™®éæ€§ï¼Œä¸‡ä¸€æœ‰ä¸ªæ²¡è§è¿‡çš„æƒ…å†µï¼Œæ•ˆæœå¯èƒ½å°±ä¸å¥½ï¼›çº¿ä¸Šä¼°è®¡çš„é€‚åº”æ€§å°±å¼ºå¾ˆå¤šï¼Œä¹Ÿä¸é‚£ä¹ˆä¾èµ–è®­ç»ƒæ ·æœ¬è´¨é‡ã€‚ä½†æ˜¯ï¼Œçº¿ä¸Šä¼°è®¡çš„æ–¹æ³•æˆ‘å‰æ®µæ—¶é—´çœ‹äº†ä¸€ä¸‹æ–‡çŒ®ï¼Œæ²¡æ€ä¹ˆçœ‹æ‡‚ã€‚å½“æ—¶æ€¥ç€æƒ³è¦çœ‹çœ‹æ•´ä½“æ–¹æ³•çš„è¡¨ç°ï¼Œå§‘ä¸”ç”¨çº¿ä¸‹å­¦ä¹ ä¼°è®¡äº†ï¼Œåˆæ­¥ç»“æœçœ‹ä¸Šå»ä¹Ÿä¸é”™ã€‚ç„¶è€Œï¼Œè¿™å‚æ•°æ™®éæ€§çš„é—®é¢˜åœ¨æˆ‘å°è¯•åšå¤§é‡ä»¿çœŸæ£€éªŒçš„æ—¶å€™ä¸å‡ºæ„å¤–åœ°å‡ºç°äº†ï¼è™½ç„¶å¿ƒé‡ŒçŸ¥é“è¿™é—®é¢˜å¾—è§£å†³ï¼Œä½†çœŸå¤„ç†èµ·è¿™æœ€åä¸€å—â€œæ‹¼å›¾â€æ—¶ï¼Œæˆ‘è¿˜æ˜¯çŠ¹è±«çš„ã€‚</p>

<p>é—®é¢˜å‘ç»™äº†è€æ¿ï¼Œå¾ˆå¿«å›å¤äº†æˆ‘ï¼šå¯ä»¥çº¿ä¸Šä¼°è®¡ï¼Œä½ çœ‹çœ‹xxxï¼ˆå‡ ä¸ªæ€æƒ³çš„å…³é”®è¯ï¼Œæ–¹ä¾¿æˆ‘å»æŸ¥é˜…ï¼‰ã€‚å¾—åˆ°å›å¤çš„æ—¶å€™æ²¡æœ‰å¤±æœ›ï¼Œåè€Œæ˜¯å®‰å¿ƒäº†ä¸€äº›ï¼Œè·Ÿè‡ªå·±è¯´ï¼Œè¸è¸å®å®åšå§ã€‚</p>

<h3 id="ä¸€ä¸ªå­¦æœŸåªè”ç³»ä¸€æ¬¡ç ”ä¸€éƒ½æ˜¯æ”¾å…»çš„å—">ä¸€ä¸ªå­¦æœŸåªè”ç³»ä¸€æ¬¡ï¼Œç ”ä¸€éƒ½æ˜¯æ”¾å…»çš„å—ï¼Ÿ</h3>

<p>å‰ä¸¤å¤©å¶ç„¶çœ‹åˆ°è±†ç“£æœ‰äººé—®äº†å¦‚ä¸Šçš„é—®é¢˜ï¼Œä»–/å¥¹çœ‹ä¸Šå»å¾ˆå›°æƒ‘ï¼Œè¯´å¸Œæœ›èƒ½è·Ÿå¯¼å¸ˆæœ‰æ›´å¤šçš„äº¤æµã€‚è›®å¤šäººå›å¤è¯´è¿™äº‹å„¿å¾—çœ‹è€å¸ˆã€‚ç¡®å®ï¼Œæ¯ä¸ªè€æ¿æŒ‡å¯¼é£æ ¼ä¸åŒä¼šæœ‰ä¸å°‘åŒºåˆ«ï¼Œä¸è¿‡è¿™åªæ˜¯å…¬å¼çš„ä¸€åŠå§ï¼Œè‡ªå·±ä½œä¸ºå¦ä¸€åŠèƒ½åšçš„äº‹å„¿ä¹Ÿå¾ˆå¤šã€‚</p>

<p>æˆ‘çš„è€æ¿ä¹Ÿæ˜¯ä¸­é—´åâ€œæ”¾å…»â€å‹çš„ï¼Œæ¯”è¾ƒå°‘ä¼šä¸»åŠ¨è¿‡é—®æˆ‘è¿›å±•å¦‚ä½•ï¼Œæ—¶ä¸æ—¶ä¼šå‘ç‚¹æ–‡ç« ç»™æˆ‘çœ‹ï¼Œä¸è¿‡æˆ‘æƒ³è®¨è®ºçš„æ—¶å€™ï¼Œä¹Ÿä¼šè®¤çœŸæŒ‡å¯¼ã€‚è®°å¾—åšä¸€åˆšå¼€å§‹é‚£ä¼šå„¿è·Ÿè€æ¿èŠè¿‡å…³äºå­¦ç”Ÿè·Ÿåšå¯¼çš„å…³ç³»ï¼Œä»–è§‰å¾—è¯»åšåšç ”ç©¶è¿™äº‹å„¿å½’æ ¹ç»“åº•æ˜¯æˆ‘ä»¬è‡ªå·±çš„ï¼Œå­¦ç”Ÿåº”è¯¥æŠŠè‡ªå·±æ”¾åˆ°é©±åŠ¨è€…çš„è§’è‰²ï¼›è€Œå¯¼å¸ˆçš„è§’è‰²åº”è¯¥æ˜¯ä¸€ä¸ªadvisor/mentorï¼Œä¼šè´Ÿè´£ç»™è¯„ä»·ã€æå»ºè®®ã€æä¾›æˆ‘éœ€è¦çš„å¸®åŠ©ï¼Œä½†å¹¶ä¸è´Ÿè´£å¸®æˆ‘åšäº‹å„¿ã€ç›‘ç£æˆ‘åšäº‹å„¿ã€‚å¯¹è¿™ï¼Œæˆ‘æ˜¯å®Œå…¨åŒæ„çš„ï¼Œå¹¶ä¸”åº†å¹¸è€æ¿åœ¨ä¸€å¼€å§‹å°±è·Ÿæˆ‘ä»¬è¯´æ¸…æ¥šã€è®©æˆ‘ä»¬æœ‰äº†åˆç†çš„æœŸå¾…(manage expectations)ã€‚</p>

<p>æˆ‘åæ¥æ„è¯†åˆ°ï¼Œæ—¢ç„¶è¦ååˆ°å¸æœºçš„ä½ç½®ä¸Šï¼Œé‚£å°±æ„å‘³ç€å¾—å­¦ä¹ æ€ä¹ˆå¼€è½¦ã€‚ä¸æ˜¯è¯´çš„å­¦ä¹ å¦‚ä½•åšæ•°å­¦æ¨å¯¼ï¼Œè€Œæ˜¯å­¦ä¹ å¦‚ä½•åšç ”ç©¶ç”Ÿï¼Œå…¶ä¸­å¾ˆé‡è¦çš„ä¸€é¡¹å°±æ˜¯å¦‚ä½•è·Ÿè€æ¿ä¿æŒæ²Ÿé€šï¼ˆå°¤å…¶æ˜¯â€œæ”¾å…»â€å‹ï¼‰ã€‚æœ‰äº›å­¦æ ¡ä¼šç»™æ–°å…¥å­¦çš„ç ”ç©¶ç”Ÿæä¾›ç±»ä¼¼åŸ¹è®­çš„è¯¾ç¨‹ï¼Œä½†ä¸æ˜¯æ‰€æœ‰å­¦æ ¡éƒ½è¿™æ ·åšã€‚åœ¨æ‘¸ç´¢çš„è¿‡ç¨‹ä¸­ï¼ŒåŒç ”ç©¶ä¸­å¿ƒçš„å¾·å›½åšååŒäº‹æ¨èäº†æœ¬å°å†Œå­ç»™æˆ‘ï¼šâ€œ<a href="/assets/month-journal/The 7 Secrets.pdf" target="_blank">The Seven Secrets of Highly Successful Research Students</a>â€ã€‚æˆ‘ä»¬ç ”ç©¶ä¸­å¿ƒæœ‰ç‚¹ç‰¹æ®Šï¼Œä¸­å¿ƒå¾ˆå¤šåšå£«éƒ½æ˜¯åœ¨ç‘å£«æ‹›äº†ç„¶åæ¥æ–°åŠ å¡è¯»çš„ï¼Œæ²¡åŠæ³•ç”¨åˆ°ç‘å£«é‚£è¾¹å¤§å­¦é‡Œçš„ä¼—å¤šèµ„æºï¼Œä»–ä»¬çš„åšå¯¼ä»¬ä¹Ÿå¤§å¤šbaseåœ¨ç‘å£«ã€‚è¿™ä¹Ÿæ˜¯å¤§å®¶æ¯”è¾ƒå…³å¿ƒâ€œå¦‚ä½•è·Ÿè€æ¿ä¿æŒæ²Ÿé€šâ€ï¼Œâ€œå¦‚ä½•æœ‰æ•ˆç®¡ç†è‡ªå·±çš„ç ”ç©¶è¿›åº¦â€ç­‰é—®é¢˜çš„åŸå› å§ã€‚å°å†Œå­é‡Œé¢ç»™å‡ºäº†è›®å¤šè¯šæ³çš„å»ºè®®ã€‚å…¶ä¸­å…³äºå¦‚ä½•è·Ÿè€æ¿ä¿æŒæ²Ÿé€šï¼Œäº¤æµå·¥ä½œçš„éƒ¨åˆ†è®©æˆ‘ä¹Ÿå—ç›ŠåŒªæµ…ã€‚å°å†Œå­æ¨èè·Ÿè€æ¿äº¤æµå·¥ä½œæ—¶ç”¨è¿™æ ·ä¸€ä¸ªæ¨¡æ¿ï¼š</p>

<ol>
  <li>è‡ªä»ä¸Šæ¬¡ä¼šè®®æˆ‘åšäº†ï¼š1..2..3..</li>
  <li>æ–°é‡åˆ°çš„é—®é¢˜ï¼š1..2..3..</li>
  <li>ï¼ˆè€æ¿çš„ï¼‰è¯„ä»·ä¸å»ºè®®ï¼š1..2..3..</li>
  <li>æ¥ä¸‹æ¥è¦åšï¼š1..2..3..</li>
</ol>

<p>è¿™æ¨¡æ¿ç”¨èµ·æ¥ç‰¹åˆ«å®¹æ˜“ä¸Šæ‰‹ã€‚æˆ‘æ˜¯æŒ‰è¿™æ ·çš„é¡ºåºä½¿ç”¨çš„ï¼šæ ¹æ®ä¸Šæ¬¡ä¼šè®®è€æ¿æå‡ºçš„è¯„ä»·ä¸å»ºè®®å»è§£å†³æˆ‘æ–°é‡åˆ°çš„é—®é¢˜ï¼Œç„¶åå»åšâ€œæ¥ä¸‹æ¥è¦åšâ€çš„äº‹å„¿ã€‚åœ¨è¿™è¿‡ç¨‹ä¸­ï¼Œå¼€å¯æ–°çš„ä¸€é¡µï¼Œå¹¶è®°å½•æ–°çš„ç¬¬ä¸€å’Œç¬¬äºŒç‚¹ï¼Œç„¶åé‡å¤ã€‚ç”¨è¿™æ¨¡æ¿è·Ÿè€æ¿åšæ¯å‘¨çš„è®¨è®ºå¿«ä¸€å¹´äº†ï¼Œè·Ÿä»¥å‰å¼€ä¼šå‰ä¸€å¤©åŒ†å¿™å‡†å¤‡è®¨è®ºçš„ç‚¹ç›¸æ¯”ï¼Œèƒ½æ˜æ˜¾æ„Ÿè§‰åˆ°ç°åœ¨è‡ªå·±åœ¨è®¨è®ºæ—¶æ€è·¯æ¸…æ™°å¾ˆå¤šï¼Œæ¯”è¾ƒå°‘å› ä¸ºè€æ¿çš„å‘æ•£æ€§æé—®è€Œå¿˜è®°åŸæœ¬æƒ³è¦è®¨è®ºçš„ç‚¹ã€‚å¦å¤–ä¸€ä¸ªæ”¹å˜æ˜¯ï¼Œå½“æˆ‘èƒ½å‚ç…§è‡ªå·±çš„è®°å½•ï¼Œæ¯”è¾ƒå‡†ç¡®åœ°è®²å‡ºè¿™é—®é¢˜çš„æ¥é¾™å»è„‰æ—¶ï¼Œå¾€å¾€èƒ½å¾—åˆ°æ¯”è¾ƒæ¸…æ™°çš„å»ºè®®ä¸è¯„ä»·ã€‚è¿™æ ·è®°å½•ä¸‹æ¥çš„ç¬”è®°ï¼Œæ—¥åå¾€å›æŸ¥çœ‹ä¹Ÿæ–¹ä¾¿å¾ˆå¤šï¼Œå°¤å…¶æ˜¯æƒ³è¦æŸ¥æ‰¾è€æ¿æ›¾ç»ç»™å‡ºçš„â€œè‡ªç›¸çŸ›ç›¾â€çš„å»ºè®®çš„æ—¶å€™ğŸ˜ƒã€‚</p>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/03/24/COVID-19.html">
        Tracking the COVID-19 outbreak and signals of containment
      </a>
    </h2>

    <span class="post-date">24 Mar 2020</span>

    <p><strong>Any conclusion drawn from the data should be viewed with caution due to the dynamic nature of a pandemic and the adundant sources of bias associated with reporting.</strong> 
I periodically update here the COVID-19 situation in the US, Europe, and Asia, tracking both the outbreak and signals of containment. The intent of this blog is not to feed daily news, but to present perspectives worth considering when reading the news. The graphs in this blog are <strong>interactive</strong> and best viewed on a desktop browser.</p>

    <!-- <p><strong>Any conclusion drawn from the data should be viewed with caution due to the dynamic nature of a pandemic and the adundant sources of bias associated with reporting.</strong> 
I periodically update here the COVID-19 situation in the US, Europe, and Asia, tracking both the outbreak and signals of containment. The intent of this blog is not to feed daily news, but to present perspectives worth considering when reading the news. The graphs in this blog are <strong>interactive</strong> and best viewed on a desktop browser.</p>

<h2 id="signals-of-containment">Signals of Containment</h2>

<p><a name="Confirmed and Death Cases"></a></p>
<h3 id="the-interplay-of-confirmed-and-death-cases">The Interplay of Confirmed and Death Cases</h3>
<p>When should the economy reopen? To try to answer this question, we could look at the interplay of new confirmed cases and death cases.</p>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=1739652220&amp;format=interactive"></iframe>
<p>More cases means more healthcare resource demand, and doctors and nurses have to make tough decisions. Unfortunately, more patients who need intensive care might not get it, leading to higher fatalities. We are probably going to see a peak in daily cases, and after some time, a peak in daily fatalities. This phenomenon is visible in the graph below. Passing the first peak means measures are taking effect; passing the second means our healthcare system is now able to cope. So, where do countries stand as of now?</p>

<p>Of course, the decision has to also depend on other factors such as the ability of testing and tracking down close contacts of those infected.</p>

<p>There are actually many questions that we could ask from this graph. For example:</p>
<ol>
  <li>Why does Germany has much higher daily confirms than Switzerland, and yet manages a much flatter death curve?</li>
  <li>Why do the two peaks for the UK seem to occur at the same time while thatâ€™s not the case for the rest?</li>
</ol>

<ul>
  <li>Countries with hopes of relaxing some of the lockdown measures: Germany and Switzerland. Both of them have passed the peaks, have low daily cases (&lt;20), and relatively flat and low death case curve (&lt;5).</li>
  <li>Countries that probably need more time: They are at the edge of passing the first peak and record about 80 daily cases. Whatâ€™s more worrying, though, is the evident pressure on the healthcare system. UK sees a drop in daily death cases, but that number is still high at 11; the USâ€™s death case curve seems not at its peak yet. They probably need more time. - April 23, 2020</li>
</ul>

<p><a name="Percentage Change"></a></p>
<h3 id="daily-case-percentage-change">Daily Case Percentage Change</h3>
<p>Look out for the 7-day moving average of the day-on-day percentage change in confirmed cases. It is important to see both the current percentage change and its trend. To easily classify the situation, we can use the following scale<sup id="fnref:percentage"><a href="#fn:percentage" class="footnote">1</a></sup>:</p>
<ul>
  <li><script type="math/tex">r > 10\%</script>: <strong>Rapidly increasing</strong>.</li>
  <li><script type="math/tex">% <![CDATA[
r < 10\% %]]></script>: <strong>Increasing</strong>.</li>
  <li><script type="math/tex">% <![CDATA[
r < 5\% %]]></script>: <strong>Slowly increasing</strong>.</li>
  <li><script type="math/tex">% <![CDATA[
r < 1\% %]]></script>: <strong>Under control</strong>.</li>
</ul>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=565833280&amp;format=interactive"></iframe>
<ul>
  <li>Japan had a turning point on 23rd March where the increase of cases started accelerating. Coincidently (or maybe not), Japan and I.O.C. officially anounced the <a href="https://www.nytimes.com/2020/03/24/sports/olympics/coronavirus-summer-olympics-postponed.html">postponement of Tokyo 2020</a> on the next day.</li>
  <li>The cases in Japan have been rising at an increasing rate, now at a 10% <a href="#Percentage Change">day-on-day growth rate</a>. Considering the exponential growth of infections, Abe, Japanese prime minister, is declaring emergency state for seven prefectures. - April 7, 2020</li>
  <li>Japan sees a slowdown of daily new cases. Itâ€™s been two weeks since the first declaration of â€œEmergency Situationâ€ by the prime minister. On average, a 50% reduction in the number of people going out in monitored areas <a href="https://www3.nhk.or.jp/news/special/coronavirus/#infection-status">are observed</a>. Meanwhile, mask sales have skyrocketed in Japan. - April 22, 2020</li>
</ul>

<p><a name="Google Search Interest"></a></p>
<h3 id="google-search-interest">Google Search Interest</h3>
<p>This figure tells us how many people in the US are searching for keywords such as â€œhand sanitizerâ€ or â€œsymptomâ€. I suspect that as the community spread of the virus is being contained, we can expect to see a drop in searches for words like â€œsymptomâ€ and â€œinfluenzaâ€, similar to the trends shown in Singapore.</p>

<p>There are drastic differences in terms of the US and Singapore google search interests during this pandemic. When signs of community infection emerged in early March, people in the US were searching for â€œsymptomâ€ at a record-high frequency, similarly for â€œinfluenzaâ€ and â€œhand sanitizerâ€. Searches for â€œmaskâ€, however, were not so heightened. The picture in Singapore looks very different. When more infections emerged inside the border in late January and early February, the search for â€œmaskâ€ shoot up rapidly, and masks went out of stock everywhere in Singapore. There are probably two main reasons for this:</p>
<ol>
  <li>A high percentage of Chinese living in Singapore;</li>
  <li>As a nation that went through SARS, it feels natural for most people to wear masks when a contagion is spreading in the community.</li>
</ol>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=783455223&amp;format=interactive"></iframe>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=196247116&amp;format=interactive"></iframe>

<p><a name="US Testing Numbers"></a></p>
<h3 id="us-testing-numbers">US Testing Numbers</h3>
<p>As the containment takes effect, we expect to see the number of positive and negative tests stabilize, and the number of tests pending result drops. As you can see, we are not there yet.</p>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=481777218&amp;format=interactive"></iframe>

<h2 id="cumulative-case-progression">Cumulative Case Progression</h2>
<hr />
<p><a name="Case progression"></a></p>
<iframe width="696.0000000000001" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=967719983&amp;format=interactive"></iframe>
<ul>
  <li>Japan has a relatively flat curve. However, there are legitimate concerns that Japan has been under-testing its population to know what is really going on. Assuming the true CFR is 1.2%<sup id="fnref:diamond_princess"><a href="#fn:diamond_princess" class="footnote">2</a></sup>, Japanâ€™s current fatality number, 77, indicates that at least 6,417 people have been infected. However, only 3,139 cases are officially confirmed as of now. Also, Japan has conducted 486 tests <a href="#https://www.worldometers.info/coronavirus/">per one million population</a>. In Singapore, that number is 11,110. - April 5, 2020.</li>
  <li>For the first time, Singapore is going into a national â€œShelter in Placeâ€ mode. The timeing is not surprising as some degree of wide-spread community infection is going on. The number of unlinked cases, those yet to find the source of infection, spiked over the last few days; Singapore also recorded 12 new clusters of infection just over the past five days (One of them is right across the river from my house). - April 5, 2020.</li>
  <li>Singapore sees a steady increase in confirmed cases, mainly in foreign worker dormitory clusters. However, if we look at the <a href="#Case progression">progression of confirmed cases</a> in Singapore, itâ€™s an almost perfect example of what â€œflatten the curveâ€ looks like. For the most part, the cases double every ten days, whereas cases in some of the worst-hit countries double every one to three days.  - April 8, 2020</li>
</ul>

<h2 id="death-cases">Death Cases</h2>
<hr />
<p><a name="case fatality rate"></a></p>
<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=366153234&amp;format=interactive"></iframe>
<ul>
  <li>Germany and Switzerland fare well in this regard and manage to record comparatively low CFRs. Austria, too, has managed one of the lowerest CFRs among European nations. Austria, Germany, and a large part of Switzerland are German-speaking.ğŸ¤”</li>
  <li>While the CFRs in Switzerland and Germany have been comparatively low, they are steadily climbing. Switzerland is probably the first country in Europe to flatten the curve, which conducted one of the highest number of tests <a href="#https://www.worldometers.info/coronavirus/">per one million population</a>. - April 10, 2020</li>
</ul>

<iframe width="696" height="432" seamless="" frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQnqDux0h60qbKyhlYff1YMpjwhPZA694IOW4ixe0XNFi-JUHjXxJ69AFIGXajrBURwUKW2FnELgE1C/pubchart?oid=709712852&amp;format=interactive"></iframe>

<p><a name="cfr bias"></a></p>
<ul>
  <li>How does selection bias affect CFR?
    <blockquote>
      <p>[In Italy], a change in strategy on Feb 25 limited testing to patients who had severe signs and symptoms also resulted in a 19% positive rate (21,157 of 109,170 tested as of Mar 14) and an apparent increase in the death rateâ€”from 3.1% on Feb 24 to 7.2% on Mar 17â€”patients with milder illness were no longer tested.  In the UK, only patients deemed ill enough to require at least one night in hospital met the criteria for a Covid-19 test.</p>

      <p>CFR rates are subject to selection bias as more severe cases are tested, generally those in the hospital settings or those with more severe symptoms. The number of currently infected asymptomatics is uncertain: estimates put it at least a half are asymptomatic; the proportion not coming forward for testing is also highly doubtful (i.e. you are symptomatic, but you do not present for testing). Therefore we can assume the IFR is significantly lower than the CFR.</p>
    </blockquote>
  </li>
  <li>When is CFR accurate?
    <blockquote>
      <p>Icelandâ€™s higher rates of testing, the smaller population, and their ability to ascertain all those with Sars-CoV-2  means they can obtain. an accurate estimate of the CFR and the infection fatality rate (IFR) during the pandemic (most countries will only be able to do this after the pandemic). Current data from Iceland suggests their IFR is somewhere between 0.01% and 0.19%.</p>
    </blockquote>
  </li>
</ul>

<p>The bottom line is, CFR is probably <strong>inflated</strong> in many countries and IFR is <strong>much lower</strong> than CFR.</p>

<h2 id="resources">Resources</h2>
<h4 id="websites">Websites</h4>
<ol>
  <li><strong>Bloomberg</strong>: <a href="https://www.bloomberg.com/graphics/2020-coronavirus-cases-world-map/?srnd=premium-asia">Mapping the Coronavirus Outbreak Across the World</a></li>
  <li><strong>Johns Hopkins University</strong>: <a href="https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6">Coronavirus COVID-19 Global Cases</a></li>
  <li><strong>Global MediXchange</strong>: <a href="https://www.alibabacloud.com/universal-service/pdf_reader?spm=a3c0i.14138300.8102420620.dreadnow.646d647fDWbsii&amp;cdnorigin=video-intl&amp;pdf=Read%20Online-Handbook%20of%20COVID-19%20Prevention%20and%20Treatment.pdf">Handbook of COVID-19 Prevention and Treatment</a></li>
</ol>

<h4 id="articles">Articles</h4>
<ol>
  <li><a href="https://www.nytimes.com/2020/03/19/us/politics/trump-coronavirus-outbreak.html">Before Virus Outbreak, a Cascade of Warnings Went Unheeded</a>, March 19, 2020</li>
  <li><a href="https://www.citylab.com/life/2020/03/coronavirus-cases-france-train-hospital-tgv-covid-19-patient/608833/">To Fight a Fast-Moving Pandemic, Get a Faster Hospital</a>, March 26, 2020</li>
  <li><a href="https://www.businessinsider.sg/coronavirus-spain-says-rapid-tests-sent-from-china-missing-cases-2020-3?_ga=2.212074516.1285585527.1585620210-963085568.1583747541&amp;r=US&amp;IR=T">Spain, Europeâ€™s worst-hit country after Italy, says coronavirus tests it bought from China are failing to detect positive cases</a>, March 26, 2020</li>
  <li><a href="https://time.com/5812555/germany-coronavirus-deaths/">Why Is Germanyâ€™s Coronavirus Death Rate So Low?</a>, March 30, 2020</li>
  <li><a href="https://www.nytimes.com/interactive/2020/04/14/science/coronavirus-transmission-cough-6-feet-ar-ul.html">This 3-D Simulation Shows Why Social Distancing Is So Important</a>, April 14, 2020</li>
</ol>

<h4 id="data-sources">Data sources</h4>
<ul>
  <li>Japan: <a href="https://www3.nhk.or.jp/news/special/coronavirus/#infection-status">NHK</a></li>
  <li>Singapore: <a href="https://www.moh.gov.sg/covid-19">Ministry of Health</a></li>
  <li>Other countries: JHU <a href="https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6">Coronavirus COVID-19 Global Cases</a></li>
  <li>US testing numbers: <a href="https://covidtracking.com/">The COIVD Tracking Project</a></li>
  <li>Search interests: <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=%2Fm%2F0b23px,%2Fm%2F01kr41,%2Fm%2F0cycc,%2Fm%2F01b_06">Google Trends</a></li>
</ul>

<h2 id="footnotes">Footnotes</h2>
<div class="footnotes">
  <ol>
    <li id="fn:percentage">
      <p>The percentage only indicates a relative change. The actual number of new cases reported in each country may be very different, as it depends on the absolute number of cumulative cases in that country.Â <a href="#fnref:percentage" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:diamond_princess">
      <p>Russell, Timothy W., et al. â€œ<a href="https://www.medrxiv.org/content/10.1101/2020.03.05.20031773v2">Estimating the infection and case fatality ratio for COVID-19 using age-adjusted data from the outbreak on the Diamond Princess cruise ship.</a>â€ medRxiv (2020).Â <a href="#fnref:diamond_princess" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/01/10/data-statistical_learning_map.html">
        Roadmap of statistical learning
      </a>
    </h2>

    <span class="post-date">10 Jan 2020</span>

    <p>A (work-in-progress) roadmap for statistical learning concepts and tools. 
<img src="/assets/ST-road-map/mindmap.png" alt="Mindmap" /></p>

    <!-- <p>A (work-in-progress) roadmap for statistical learning concepts and tools. 
<img src="/assets/ST-road-map/mindmap.png" alt="Mindmap" /></p>

<p><strong>Regression</strong></p>
<ol>
  <li>Regularised Linear Regression
    <ul>
      <li>Ridge regression</li>
      <li>Lasso regression</li>
      <li>Logistic (ridge/lasso) regression</li>
    </ul>
  </li>
</ol>

<p>Next: however, linear relationship might be too restrictive in many cases, we wish to allow nonlinear relationship between response and predictors.</p>

<ol>
  <li>Basis Expansion Method
    <ul>
      <li>Approximate mean function in a piecewise way
        <ul>
          <li>kth order spline for kth order piece, i.e. cubic spline means each segment is approximated by a cubic function formed by basis functions</li>
          <li>Positive part remain operator (x - r)+ to ensure continuity at knots</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Additive Model (semi-parametric method, building on top of basis expansion method)
    <ul>
      <li>More flexible than linear but retains the interpretability
        <ul>
          <li>Partially linear additive model: summation of linear variables and functions of variable
            <ul>
              <li>Nonlinear variables can be assumed to be represented by spline basis</li>
              <li>What if a variable influences the relationship between Y and X?
                <ul>
                  <li>Varying coefficient regression model: variable coefficients are functions of a variable(Z)</li>
                  <li>Such function can be assumed to have good estimation by spline method</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Generalised: extend the method beyond linear link function, e.g. logistic</li>
      <li>If we approximate each additive variable by piecewise linear model: multivariate adaptive regression spline (MARS)</li>
    </ul>
  </li>
  <li>Local Averaging Method
    <ul>
      <li>To estimate the regression surface, we can use local averaging method by defining two things
        <ol>
          <li>What is â€œlocalâ€? i.e. how do we partition the space/find out the regression surface?</li>
          <li>How to compute â€œaverageâ€? i.e. simple average, weighted average?</li>
        </ol>
      </li>
      <li>Point 1 above
        <ul>
          <li>Binary recursive method: Regression and classification tree (CART)</li>
          <li>Neighbourhood method: identifies a neighbour through some metric (kNN)</li>
        </ul>
      </li>
      <li>Point 2 above
        <ul>
          <li>Simple average: CART, kNN</li>
          <li>Weighted average: weighted kNN, see point 7 below</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>But this kind of method produces non-smooth m(x) estimation since the weight used is indicator function.</p>

<ol>
  <li>Kernel Smoothing
    <ul>
      <li>Replace the indicator function by a kernel function (symmetric pdf)</li>
      <li>Nadaraya-Watson (NW) estimator: least square estimator weighted by kernel function</li>
      <li>The value of h defines the size of the neighbourhood</li>
      <li>Hence h determines the trade-off between model complexity and stability</li>
      <li>But y need not be locally constant (regression tree, kNN, KS), we can assume y is locally linear or polynomial
        <ul>
          <li>LLKS</li>
          <li>LPKS</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Next: But the MSE of KS (nonparametric) methods increases with p (CoD). We can do dimension reduction, besides assuming a structure for m(x).</li>
  <li>Dimension-reduction based method
    <ol>
      <li>Ridge function = 1: Single-index model: one projection direction, in terms of unknown link function
        <ul>
          <li>More flexible than linear regression, but also more interpretable than PPR</li>
        </ul>
      </li>
      <li>Ridge function &gt; 1: Projection pursuit regression: one projection direction for each ridge function
        <ul>
          <li>Approximate target by non-linear function of the linear combination of input</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>Machine Learning
    <ul>
      <li>Without assuming the model of the data, learning a function that maps features (X) to predictions (Y), assume a space of the function (linear space, non-linear space), assume a convex loss/risk function (square error function).</li>
      <li>Representer theorem provides the theoretical foundation for functions from RKHS to approximate the relationship by assuming a certain kernel, which is defined by the kind of kernel.</li>
      <li>Support Vector Machine: learning the location of the support vectors and the value of alpha for the kernel of support vectors, i.e. linear kernel, gaussian kernel, rbf kernel.</li>
      <li>How is it different (performance, computation and etc.) for low and high dimensional case when we use non-linear kernel SVM?</li>
      <li>Classification
        <ul>
          <li>Fisherâ€™s linear discriminant: linear combination of dimensions of X -&gt; find a linear hyperplane that maximally separates the linear combination and minimises the variance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Classification</strong></p>
<ol>
  <li>Linear methods
    <ul>
      <li>Linear regression</li>
      <li>Linear discriminant analysis</li>
    </ul>
  </li>
  <li>Non-linear methods
    <ul>
      <li>SVM</li>
      <li>Discriminant analysis
        <ol>
          <li>QDA ( assume unequal variance)</li>
          <li>Flexible discriminant analysis</li>
          <li>Mixture discriminant analysis</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Bayesian Inference</strong></p>
<ol>
  <li>Inference for dynamic systems/state-space models(SSMs)
    <ul>
      <li>Finite SSM: Baum-Petrie filter is the optimal filter with O(K^2) complexity.</li>
      <li>Linear-Gaussian SSM: Kalman filter is the optimal filter, propagate mean and variance for inference.</li>
      <li>Non-linear dynamics and/or non-Gaussian noise:
        <ol>
          <li>Extended Kalman filter</li>
          <li>Unscented Kalman filter</li>
          <li>Sequential Monte Carlo (Particle filters) methods can be used since the distribution information is preserved beyond mean and covariance:
            <ol>
              <li>Importance sampling to tackle difficult-to-sample posterior distribution problem</li>
              <li>Recursive formulation to tackle online inference complexity problem</li>
              <li>Resampling to ensure long-term stability of the particle method (mitigates sample impoverishment)</li>
            </ol>
          </li>
          <li>Particle filtering
            <ol>
              <li></li>
            </ol>
          </li>
          <li>Particle smoothing</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/01/10/data-line-outage-detection-via-sequential-hypothesis-testing.html">
        Roadmap of statistical learning
      </a>
    </h2>

    <span class="post-date">10 Jan 2020</span>

    <p>A (work-in-progress) roadmap for statistical learning concepts and tools.</p>

    <!-- <p>A (work-in-progress) roadmap for statistical learning concepts and tools.</p>

<p><strong>Regression</strong></p>
<ol>
  <li>Regularised Linear Regression
    <ul>
      <li>Ridge regression</li>
      <li>Lasso regression</li>
      <li>Logistic (ridge/lasso) regression</li>
    </ul>
  </li>
</ol>

<p>Next: however, linear relationship might be too restrictive in many cases, we wish to allow nonlinear relationship between response and predictors.</p>

<ol>
  <li>Basis Expansion Method
    <ul>
      <li>Approximate mean function in a piecewise way
        <ul>
          <li>kth order spline for kth order piece, i.e. cubic spline means each segment is approximated by a cubic function formed by basis functions</li>
          <li>Positive part remain operator (x - r)+ to ensure continuity at knots</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Additive Model (semi-parametric method, building on top of basis expansion method)
    <ul>
      <li>More flexible than linear but retains the interpretability
        <ul>
          <li>Partially linear additive model: summation of linear variables and functions of variable
            <ul>
              <li>Nonlinear variables can be assumed to be represented by spline basis</li>
              <li>What if a variable influences the relationship between Y and X?
                <ul>
                  <li>Varying coefficient regression model: variable coefficients are functions of a variable(Z)</li>
                  <li>Such function can be assumed to have good estimation by spline method</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Generalised: extend the method beyond linear link function, e.g. logistic</li>
      <li>If we approximate each additive variable by piecewise linear model: multivariate adaptive regression spline (MARS)</li>
    </ul>
  </li>
  <li>Local Averaging Method
    <ul>
      <li>To estimate the regression surface, we can use local averaging method by defining two things
        <ol>
          <li>What is â€œlocalâ€? i.e. how do we partition the space/find out the regression surface?</li>
          <li>How to compute â€œaverageâ€? i.e. simple average, weighted average?</li>
        </ol>
      </li>
      <li>Point 1 above
        <ul>
          <li>Binary recursive method: Regression and classification tree (CART)</li>
          <li>Neighbourhood method: identifies a neighbour through some metric (kNN)</li>
        </ul>
      </li>
      <li>Point 2 above
        <ul>
          <li>Simple average: CART, kNN</li>
          <li>Weighted average: weighted kNN, see point 7 below</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>But this kind of method produces non-smooth m(x) estimation since the weight used is indicator function.</p>

<ol>
  <li>Kernel Smoothing
    <ul>
      <li>Replace the indicator function by a kernel function (symmetric pdf)</li>
      <li>Nadaraya-Watson (NW) estimator: least square estimator weighted by kernel function</li>
      <li>The value of h defines the size of the neighbourhood</li>
      <li>Hence h determines the trade-off between model complexity and stability</li>
      <li>But y need not be locally constant (regression tree, kNN, KS), we can assume y is locally linear or polynomial
        <ul>
          <li>LLKS</li>
          <li>LPKS</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Next: But the MSE of KS (nonparametric) methods increases with p (CoD). We can do dimension reduction, besides assuming a structure for m(x).</li>
  <li>Dimension-reduction based method
    <ol>
      <li>Ridge function = 1: Single-index model: one projection direction, in terms of unknown link function
        <ul>
          <li>More flexible than linear regression, but also more interpretable than PPR</li>
        </ul>
      </li>
      <li>Ridge function &gt; 1: Projection pursuit regression: one projection direction for each ridge function
        <ul>
          <li>Approximate target by non-linear function of the linear combination of input</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>Machine Learning
    <ul>
      <li>Without assuming the model of the data, learning a function that maps features (X) to predictions (Y), assume a space of the function (linear space, non-linear space), assume a convex loss/risk function (square error function).</li>
      <li>Representer theorem provides the theoretical foundation for functions from RKHS to approximate the relationship by assuming a certain kernel, which is defined by the kind of kernel.</li>
      <li>Support Vector Machine: learning the location of the support vectors and the value of alpha for the kernel of support vectors, i.e. linear kernel, gaussian kernel, rbf kernel.</li>
      <li>How is it different (performance, computation and etc.) for low and high dimensional case when we use non-linear kernel SVM?</li>
      <li>Classification
        <ul>
          <li>Fisherâ€™s linear discriminant: linear combination of dimensions of X -&gt; find a linear hyperplane that maximally separates the linear combination and minimises the variance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Classification</strong></p>
<ol>
  <li>Linear methods
    <ul>
      <li>Linear regression</li>
      <li>Linear discriminant analysis</li>
    </ul>
  </li>
  <li>Non-linear methods
    <ul>
      <li>SVM</li>
      <li>Discriminant analysis
        <ol>
          <li>QDA ( assume unequal variance)</li>
          <li>Flexible discriminant analysis</li>
          <li>Mixture discriminant analysis</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Bayesian Inference</strong></p>
<ol>
  <li>Inference for dynamic systems/state-space models(SSMs)
    <ul>
      <li>Finite SSM: Baum-Petrie filter is the optimal filter with O(K^2) complexity.</li>
      <li>Linear-Gaussian SSM: Kalman filter is the optimal filter, propagate mean and variance for inference.</li>
      <li>Non-linear dynamics and/or non-Gaussian noise:
        <ol>
          <li>Extended Kalman filter</li>
          <li>Unscented Kalman filter</li>
          <li>Sequential Monte Carlo (Particle filters) methods can be used since the distribution information is preserved beyond mean and covariance:
            <ol>
              <li>Importance sampling to tackle difficult-to-sample posterior distribution problem</li>
              <li>Recursive formulation to tackle online inference complexity problem</li>
              <li>Resampling to ensure long-term stability of the particle method (mitigates sample impoverishment)</li>
            </ol>
          </li>
          <li>Particle filtering
            <ol>
              <li></li>
            </ol>
          </li>
          <li>Particle smoothing</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/01/10/data-line-outage-detection-based-on-particle-filtering.html">
        Roadmap of statistical learning
      </a>
    </h2>

    <span class="post-date">10 Jan 2020</span>

    <p>A (work-in-progress) roadmap for statistical learning concepts and tools.</p>

    <!-- <p>A (work-in-progress) roadmap for statistical learning concepts and tools.</p>

<p><strong>Regression</strong></p>
<ol>
  <li>Regularised Linear Regression
    <ul>
      <li>Ridge regression</li>
      <li>Lasso regression</li>
      <li>Logistic (ridge/lasso) regression</li>
    </ul>
  </li>
</ol>

<p>Next: however, linear relationship might be too restrictive in many cases, we wish to allow nonlinear relationship between response and predictors.</p>

<ol>
  <li>Basis Expansion Method
    <ul>
      <li>Approximate mean function in a piecewise way
        <ul>
          <li>kth order spline for kth order piece, i.e. cubic spline means each segment is approximated by a cubic function formed by basis functions</li>
          <li>Positive part remain operator (x - r)+ to ensure continuity at knots</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Additive Model (semi-parametric method, building on top of basis expansion method)
    <ul>
      <li>More flexible than linear but retains the interpretability
        <ul>
          <li>Partially linear additive model: summation of linear variables and functions of variable
            <ul>
              <li>Nonlinear variables can be assumed to be represented by spline basis</li>
              <li>What if a variable influences the relationship between Y and X?
                <ul>
                  <li>Varying coefficient regression model: variable coefficients are functions of a variable(Z)</li>
                  <li>Such function can be assumed to have good estimation by spline method</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Generalised: extend the method beyond linear link function, e.g. logistic</li>
      <li>If we approximate each additive variable by piecewise linear model: multivariate adaptive regression spline (MARS)</li>
    </ul>
  </li>
  <li>Local Averaging Method
    <ul>
      <li>To estimate the regression surface, we can use local averaging method by defining two things
        <ol>
          <li>What is â€œlocalâ€? i.e. how do we partition the space/find out the regression surface?</li>
          <li>How to compute â€œaverageâ€? i.e. simple average, weighted average?</li>
        </ol>
      </li>
      <li>Point 1 above
        <ul>
          <li>Binary recursive method: Regression and classification tree (CART)</li>
          <li>Neighbourhood method: identifies a neighbour through some metric (kNN)</li>
        </ul>
      </li>
      <li>Point 2 above
        <ul>
          <li>Simple average: CART, kNN</li>
          <li>Weighted average: weighted kNN, see point 7 below</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>But this kind of method produces non-smooth m(x) estimation since the weight used is indicator function.</p>

<ol>
  <li>Kernel Smoothing
    <ul>
      <li>Replace the indicator function by a kernel function (symmetric pdf)</li>
      <li>Nadaraya-Watson (NW) estimator: least square estimator weighted by kernel function</li>
      <li>The value of h defines the size of the neighbourhood</li>
      <li>Hence h determines the trade-off between model complexity and stability</li>
      <li>But y need not be locally constant (regression tree, kNN, KS), we can assume y is locally linear or polynomial
        <ul>
          <li>LLKS</li>
          <li>LPKS</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Next: But the MSE of KS (nonparametric) methods increases with p (CoD). We can do dimension reduction, besides assuming a structure for m(x).</li>
  <li>Dimension-reduction based method
    <ol>
      <li>Ridge function = 1: Single-index model: one projection direction, in terms of unknown link function
        <ul>
          <li>More flexible than linear regression, but also more interpretable than PPR</li>
        </ul>
      </li>
      <li>Ridge function &gt; 1: Projection pursuit regression: one projection direction for each ridge function
        <ul>
          <li>Approximate target by non-linear function of the linear combination of input</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>Machine Learning
    <ul>
      <li>Without assuming the model of the data, learning a function that maps features (X) to predictions (Y), assume a space of the function (linear space, non-linear space), assume a convex loss/risk function (square error function).</li>
      <li>Representer theorem provides the theoretical foundation for functions from RKHS to approximate the relationship by assuming a certain kernel, which is defined by the kind of kernel.</li>
      <li>Support Vector Machine: learning the location of the support vectors and the value of alpha for the kernel of support vectors, i.e. linear kernel, gaussian kernel, rbf kernel.</li>
      <li>How is it different (performance, computation and etc.) for low and high dimensional case when we use non-linear kernel SVM?</li>
      <li>Classification
        <ul>
          <li>Fisherâ€™s linear discriminant: linear combination of dimensions of X -&gt; find a linear hyperplane that maximally separates the linear combination and minimises the variance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Classification</strong></p>
<ol>
  <li>Linear methods
    <ul>
      <li>Linear regression</li>
      <li>Linear discriminant analysis</li>
    </ul>
  </li>
  <li>Non-linear methods
    <ul>
      <li>SVM</li>
      <li>Discriminant analysis
        <ol>
          <li>QDA ( assume unequal variance)</li>
          <li>Flexible discriminant analysis</li>
          <li>Mixture discriminant analysis</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Bayesian Inference</strong></p>
<ol>
  <li>Inference for dynamic systems/state-space models(SSMs)
    <ul>
      <li>Finite SSM: Baum-Petrie filter is the optimal filter with O(K^2) complexity.</li>
      <li>Linear-Gaussian SSM: Kalman filter is the optimal filter, propagate mean and variance for inference.</li>
      <li>Non-linear dynamics and/or non-Gaussian noise:
        <ol>
          <li>Extended Kalman filter</li>
          <li>Unscented Kalman filter</li>
          <li>Sequential Monte Carlo (Particle filters) methods can be used since the distribution information is preserved beyond mean and covariance:
            <ol>
              <li>Importance sampling to tackle difficult-to-sample posterior distribution problem</li>
              <li>Recursive formulation to tackle online inference complexity problem</li>
              <li>Resampling to ensure long-term stability of the particle method (mitigates sample impoverishment)</li>
            </ol>
          </li>
          <li>Particle filtering
            <ol>
              <li></li>
            </ol>
          </li>
          <li>Particle smoothing</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/data/2020/01/10/data-introduction-to-particle-filtering.html">
        Particle filtering: vallina and advanced
      </a>
    </h2>

    <span class="post-date">10 Jan 2020</span>

    <p>The problem - Non-linear dynamic state estimation</p>
<ul>
  <li>state-space model for dynamic systems</li>
</ul>

    <!-- <p>The problem - Non-linear dynamic state estimation</p>
<ul>
  <li>state-space model for dynamic systems</li>
</ul>

<p>Other methods - Kalman-based fiter?</p>
<ul>
  <li>limitations</li>
</ul>

<p>The method - Bayesian estimation through Monte Carlo method</p>
<ul>
  <li>Bayesian estimation</li>
  <li>Monte Carlo method</li>
</ul>

 -->
  </div>
  
  <div class="post">
    <h2 class="post-title">
      <a href="/reading/2019/11/12/how-to-read.html">
        è¯»ä¹¦ç¬”è®°ï¼šè¯»ä¹¦ä½“éªŒæ˜¯ä»€ä¹ˆ
      </a>
    </h2>

    <span class="post-date">12 Nov 2019</span>

    <p>æˆ‘æœ‰é€‰ä¹¦è´­ä¹¦çš„ä¹ æƒ¯ï¼Œä¹Ÿæœ‰é€›ä¹¦åº—èŠ±äº”åˆ†é’Ÿå†³å®šå¸¦å›å“ªæœ¬ä¹¦çš„æ—¶å€™ï¼›æˆ‘æ—¶ä¸æ—¶è¯»ä¹¦ï¼Œä½†å¾€å¾€è¯»å®Œä¹‹åå¿˜æ‰ä¹¦é‡Œæœ‰ä»€ä¹ˆç²¾å½©å†…å®¹ï¼›æˆ‘æœ‰åœ¨ç•™ç™½è¯„è®ºçš„ä¹ æƒ¯ï¼Œä¹Ÿæœ‰ä¸å†ç¿»çœ‹å½“æ—¶å†™ä¸‹çš„è¯„è®ºã€è§‚ç‚¹çš„ä¹ æƒ¯ã€‚å®¶é‡Œæœªæ‹†å°çš„ä¹¦è¶Šæ¥è¶Šå¤šï¼Œæ–­æ–­ç»­ç»­åœ¨è¯»çš„ä¹¦å…·ä½“ä¹Ÿè¯´ä¸å‡ºæ¥å“ªé‡Œå¸å¼•æˆ‘ï¼Œè¯»è¿‡çš„ä¹¦å¥½åƒè¢«å¿«é€Ÿæ¶ˆè´¹è¿‡ä¸€æ ·æ²¡å†éœ²è„¸ã€‚å¦ç™½è®²ï¼Œæˆ‘å¹¶ä¸äº†è§£åº”è¯¥å¦‚ä½•è¯»ä¹¦å§ã€‚å¹¸è¿çš„æ˜¯ï¼Œå¥¥é‡å®£ä¹‹åœ¨ä»–çš„ã€Šå¦‚ä½•æœ‰æ•ˆé˜…è¯»ä¸€æœ¬ä¹¦ã€‹é‡Œæä¾›äº†æ¸…æ™°çš„æ–¹æ³•ã€‚</p>

    <!-- <p>æˆ‘æœ‰é€‰ä¹¦è´­ä¹¦çš„ä¹ æƒ¯ï¼Œä¹Ÿæœ‰é€›ä¹¦åº—èŠ±äº”åˆ†é’Ÿå†³å®šå¸¦å›å“ªæœ¬ä¹¦çš„æ—¶å€™ï¼›æˆ‘æ—¶ä¸æ—¶è¯»ä¹¦ï¼Œä½†å¾€å¾€è¯»å®Œä¹‹åå¿˜æ‰ä¹¦é‡Œæœ‰ä»€ä¹ˆç²¾å½©å†…å®¹ï¼›æˆ‘æœ‰åœ¨ç•™ç™½è¯„è®ºçš„ä¹ æƒ¯ï¼Œä¹Ÿæœ‰ä¸å†ç¿»çœ‹å½“æ—¶å†™ä¸‹çš„è¯„è®ºã€è§‚ç‚¹çš„ä¹ æƒ¯ã€‚å®¶é‡Œæœªæ‹†å°çš„ä¹¦è¶Šæ¥è¶Šå¤šï¼Œæ–­æ–­ç»­ç»­åœ¨è¯»çš„ä¹¦å…·ä½“ä¹Ÿè¯´ä¸å‡ºæ¥å“ªé‡Œå¸å¼•æˆ‘ï¼Œè¯»è¿‡çš„ä¹¦å¥½åƒè¢«å¿«é€Ÿæ¶ˆè´¹è¿‡ä¸€æ ·æ²¡å†éœ²è„¸ã€‚å¦ç™½è®²ï¼Œæˆ‘å¹¶ä¸äº†è§£åº”è¯¥å¦‚ä½•è¯»ä¹¦å§ã€‚å¹¸è¿çš„æ˜¯ï¼Œå¥¥é‡å®£ä¹‹åœ¨ä»–çš„ã€Šå¦‚ä½•æœ‰æ•ˆé˜…è¯»ä¸€æœ¬ä¹¦ã€‹é‡Œæä¾›äº†æ¸…æ™°çš„æ–¹æ³•ã€‚</p>

<p style="display: block; margin-left: auto; margin-right: auto; width: 50%;"><img src="/assets/2019-11-12/book_cover.jpg" alt="cover" /></p>
<ul>
  <li>ä¹¦åï¼š<a href="https://book.douban.com/subject/26789567/">å¦‚ä½•æœ‰æ•ˆé˜…è¯»ä¸€æœ¬ä¹¦</a></li>
  <li>åŸåï¼šèª­æ›¸ã¯1å†Šã®ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ãªã•ã„</li>
  <li>ä½œè€…ï¼š<a href="http://okuno0904.com/about/index.html">å¥¥é‡å®£ä¹‹</a>ï¼ˆãŠãã®ãƒ»ã®ã¶ã‚†ãï¼‰</li>
  <li>è´­å…¥æ—¥æœŸï¼š2019.11.11ï¼ˆæ‰“æŠ˜ï¼ï¼‰</li>
</ul>

<h3 id="è¯»ä¹¦ä½“éªŒ">è¯»ä¹¦ä½“éªŒ</h3>
<p>è¿™æœ¬149é¡µçš„å°ä¹¦ï¼Œæˆ‘è§‰å¾—å¯ä»¥çœ‹åšæ˜¯â€œå¦‚ä½•è¯»ä¹¦â€çš„ä¸€æœ¬å‚è€ƒä¹¦ï¼›é‡Œé¢ä»‹ç»çš„è§‚ç‚¹å’Œæ–¹æ³•ï¼Œä¸åŒçº§åˆ«çš„è¯»è€…éƒ½å¯ä»¥åœ¨é€‚å½“çš„æ—¶å€™è¯»ä¸€è¯»ï¼Œå¹¶å­¦åˆ°äº›ä¸œè¥¿ã€‚è¿™æœ¬å°ä¹¦æ—¨åœ¨å›ç­”è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šå¦‚ä½•æ‰èƒ½ä¸å¿˜è®°è¯»è¿‡çš„ä¹¦ä¸­çš„å†…å®¹ï¼Œå¹¶ä½¿ä¹‹èå…¥èº«å¿ƒï¼ŒçœŸæ­£ä½¿ä¹¦ç±å½±å“è‡ªå·±ï¼Ÿ</p>

<p>è€Œä»–çš„å›ç­”æ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥é‡æ–°æ€è€ƒè¯»ä¹¦è¿™ä»¶äº‹å„¿ã€‚è¯»ä¹¦ä¸åº”å§‹äºç¿»å¼€ä¹¦ç±ï¼Œä¹Ÿä¸ç»ˆäºæœ€åä¸€é¡µã€‚æ¯ä¸€æ¬¡è¯»ä¹¦ï¼Œæˆ‘ä»¬åº”è¯¥å»åˆ›é€ å±äºè‡ªå·±çš„â€œè¯»ä¹¦ä½“éªŒâ€ã€‚è¦å¦‚ä½•ç†è§£è¿™ä¸ªâ€œä½“éªŒâ€å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥æƒ³æƒ³ç”Ÿæ´»ä¸­çš„å…¶ä»–ä½“éªŒï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ä½“éªŒã€‚æˆ‘ä¸ç»å¸¸ä¹°ä¸œè¥¿ï¼Œä½†å¦‚æœè¦ä¹°ä»€ä¹ˆï¼Œä¼šå°½é‡å»æƒ³æ¸…æ¥šä¸ºä»€ä¹ˆè¦ä¹°ï¼Œä¼šæå‰å»äº†è§£è¿™ä¸ªä¸œè¥¿çš„èƒŒæ™¯ï¼ŒåŠŸèƒ½ï¼Œè¯„ä»·ï¼Œä½¿ç”¨è¿‡ç¨‹ä¸­ä¼šä¸æ–­æ›´æ–°æœ€åˆçš„è®¾æƒ³ï¼Œå¹¶æŒç»­å½±å“æˆ‘ä¸‹ä¸€æ¬¡è´­ç‰©çš„åˆ¤æ–­ã€‚è¿™ä¹Ÿå°±æ˜¯ä¸€æ¬¡æœ‰æ„è¯†æœ‰ç›®çš„èƒ½å½±å“æœªæ¥çš„è´­ç‰©ä½“éªŒã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½œè€…æ¨å´‡çš„æ˜¯ä¸€ç§æœ‰ç›®çš„èƒ½é‡æ¸©ã€ç”šè‡³å†ä¹…å¼¥æ–°çš„è¯»ä¹¦ä½“éªŒã€‚å®é™…ä¸Šï¼Œä½œè€…ä¹Ÿè®¤ä¸ºï¼Œè¿™æ ·çš„è¯»ä¹¦ä½“éªŒæ¯”ä¹¦æœ¬èº«é‡è¦å¤šäº†ã€‚</p>

<p>ä½œè€…æ€»ç»“äº†ä¸‹é¢äº”ä¸ªå…·ä½“å¯è¡Œçš„æ­¥éª¤æ¥åˆ›é€ æ‰€è°“çš„è¯»ä¹¦ä½“éªŒï¼š</p>
<ol>
  <li><strong>é€‰ä¹¦</strong>ï¼šæ”¶é›†éšæƒ³ï¼Œå»ºç«‹ç›®çš„</li>
  <li><strong>è´­ä¹¦</strong>ï¼šå†·é™è¯„ä¼°ï¼Œä¹¦ç±ç¡®è®¤</li>
  <li><strong>è¯»ä¹¦</strong>ï¼šé€‚å½“æ ‡è®°ï¼Œæç‚¼é‡ç‚¹</li>
  <li><strong>è®°å½•</strong>ï¼šåŸæ–‡æ‘˜æŠ„ï¼ŒåŸåˆ›æ€è€ƒ</li>
  <li><strong>æ´»ç”¨</strong>ï¼šé‡è¯»ç¬”è®°ï¼Œæ€æƒ³è¾“å‡º</li>
</ol>

<p>è€Œåœ¨ä½œè€…çš„å¿ƒä¸­ï¼Œåˆ›é€ è¿™ä¸ªè¯»ä¹¦ä½“éªŒå¿…ä¸å¯å°‘çš„ä¼™ä¼´æ˜¯ä¸€ä¸ªæ™®é€šçš„ç¬”è®°æœ¬ã€‚å› ä¸ºå®ƒåœ¨ä¸Šé¢äº”ä¸ªæ­¥éª¤ä¸­æ‰€å‘æŒ¥çš„é‡è¦ä½œç”¨ï¼Œè¿™ç¬”è®°æœ¬åº”æ—¶å¸¸ä¼´æˆ‘ä»¬å·¦å³ï¼Œå¹¶ä¸”ï¼Œå¦‚æœç›´è¯‘æœ¬ä¹¦çš„åŸä¹¦åï¼Œä½ ä¼šå‘ç°ï¼Œå®ƒå…¶å®æ„æ€æ˜¯â€œè¯·ç”¨ä¸€ä¸ªç¬”è®°æœ¬æ•´ç†ä½ çš„è¯»ä¹¦â€ã€‚</p>

<h3 id="ç”¨è´­ä¹¦æ¸…å•æŒ‡åè´­ä¹¦">ç”¨è´­ä¹¦æ¸…å•æŒ‡åè´­ä¹¦</h3>
<p>åˆ›é€ è¯»ä¹¦ä½“éªŒçš„ç¬¬ä¸€æ­¥ï¼Œæ˜¯ç»™è‡ªå·±å¼€å‡ºä¸€ä¸ªè´­ä¹¦æ¸…å•ã€‚å¼€æ¸…å•ä¸æ˜¯ä¸ºäº†é€›ä¹¦åº—çš„æ—¶å€™å®¹æ˜“æ‰¾ï¼ˆä¹Ÿæœ‰è¿™å¥½å¤„ï¼‰ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œè®©æˆ‘ä»¬èƒ½æ¸…æ¥šè®¤è¯†åˆ°è¯»æ¯ä¸€æœ¬ä¹¦çš„ç›®çš„æ˜¯ä»€ä¹ˆã€‚ä½œè€…æ˜¯è¿™ä¹ˆè¯´çš„ï¼š</p>
<blockquote>
  <p>é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆè¦æŠŠåˆ—æ¸…å•çš„è¿‡ç¨‹ä¹Ÿä½œä¸ºè¯»ä¹¦æ–¹æ³•çš„ä¸€éƒ¨åˆ†æ¥è¯´æ˜å‘¢ï¼Ÿç†ç”±ä¹‹ä¸€ï¼Œå°±æ˜¯è¦åŸ¹å…»å¸¦ç€ç›®çš„å»è¯»ä¹¦çš„ç›®çš„æ„è¯†ã€‚</p>
</blockquote>

<p>ä¸‹é¢æ˜¯ä½œè€…æ¨èçš„é€‰ä¹¦è´­ä¹¦çš„å…·ä½“æ“ä½œæ­¥éª¤ï¼š</p>

<blockquote>
  <p><strong>å¥½å¥‡å¿ƒæ¿€å‘</strong> â†’ <strong>éšæƒ³ç¬”è®°</strong> â†’ <strong>è´­ä¹¦æ¸…å•</strong> â†’ <strong>è´­ä¹¦</strong></p>
</blockquote>

<p>ç¬¬ä¸€æ­¥æ˜¯å°†æ¿€å‘å¥½å¥‡å¿ƒçš„æºå¤´è®°è¿›ç¬”è®°æœ¬é‡Œï¼Œå¯ä»¥å«åšéšæƒ³ç¬”è®°ã€‚è¿™æºå¤´çš„å¯èƒ½æ€§å°±å¾ˆå¤šäº†ï¼š</p>
<ul>
  <li>æŠ¥åˆŠä¸Šè¯»åˆ°æœ‰æ„æ€çš„ä¹¦è¯„</li>
  <li>å¬åˆ°æ„Ÿå…´è¶£çš„æ”¿æ²»æ—¶äº‹è¯„è®º</li>
  <li>æ¥è‡ªæœ‹å‹çš„ä¹¦ç±æ¨è</li>
  <li>ç­‰ç­‰</li>
</ul>

<p>åªè¦æ˜¯æ¿€èµ·äº†æˆ‘ä»¬å¥½å¥‡å¿ƒçš„ä¸œè¥¿ï¼Œéƒ½åº”è¯¥è®°è¿›éšæƒ³ç¬”è®°é‡Œå»ã€‚ä¹‹åä¾¿èƒ½æ ¹æ®éšæƒ³ç¬”è®°ï¼Œå»ºç«‹èµ·è¯»ä¹¦çš„ç›®çš„ï¼Œå¹¶å»å¯»æ‰¾ç›¸å…³ä¹¦ç±ã€‚åœ¨ç»è¿‡å†·é™çš„è¯„ä¼°ä¹‹åï¼Œå°†æƒ³è¦è´­ä¹°çš„ä¹¦ç±åˆ—è¿›æ¸…å•ã€‚è¿™æµç¨‹çš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬ç›¸å¯¹èƒ½å¤Ÿå‡†ç¡®åœ°é€‰å‡ºè‡ªå·±çœŸæ­£æƒ³è¯»å¹¶ä¸”æ˜ç™½ä¸ºä»€ä¹ˆæƒ³è¯»çš„ä¹¦ï¼Œè¿™æ ·ä¹°å›æ¥æ„Ÿå…´è¶£ã€è¯»ä¸‹å»çš„å‡ ç‡éƒ½æ¯”è¾ƒé«˜ï¼ˆè¿™ä¸ªå¾ˆé‡è¦ğŸ˜‚ï¼‰ã€‚å¹¶ä¸”ï¼Œåœ¨è¯»ä¹¦è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å¸¦ç€æœ€åˆè¢«æ¿€å‘çš„å¥½å¥‡å¿ƒå»è¯»ï¼Œè¯»å®Œä¹‹åä¹Ÿèƒ½å›é¡¾ä¸€å¼€å§‹å¥½å¥‡å¿ƒè¢«æ¿€å‘çš„å¥‘æœºï¼Œå› ä¸ºè¿™äº›éƒ½è¢«ä¸€ä¸€è®°å½•åœ¨ç¬”è®°æœ¬é‡Œã€‚</p>

<h3 id="ç”¨ç¬”è®°æŠŠè¯»è¿‡çš„ä¹¦å˜ä¸ºç²¾ç¥è´¢å¯Œ">ç”¨ç¬”è®°æŠŠè¯»è¿‡çš„ä¹¦å˜ä¸ºç²¾ç¥è´¢å¯Œ</h3>
<p>è¿™é‡Œè®²çš„åŒ…å«äº†æ­¥éª¤ä¸‰å’Œå››ï¼šè¯»ä¹¦ï¼Œè®°å½•ã€‚</p>

<p>è¯»ä¹¦çš„æ—¶å€™ï¼Œæˆ‘ä»¬éµå¾ªè¿™æ ·ä¸€ä¸ªæµç¨‹ï¼šé€šè¯» â†’ ç‰‡æ®µé‡è¯» â†’ æ ‡è®°ã€‚æ„æ€å°±æ˜¯ï¼Œé€šè¯»ä¹‹åï¼Œå»é‡è¯»ä½ æ„Ÿåˆ°æœ‰å…±é¸£ã€ç–‘æƒ‘ã€æ„Ÿå…´è¶£ç­‰ç­‰çš„ç‰‡æ®µï¼Œæœ‰å¿…è¦å°±ç”¨ç»Ÿä¸€ç¬¦å·æ ‡è®°ä¸‹æ¥ï¼Œæ¯”å¦‚ï¼š</p>
<ul>
  <li>ä¸‹åˆ’ç›´çº¿ ï¼¿ï¼¿ï¼šå®¢è§‚é‡è¦</li>
  <li>ä¸‹åˆ’æ³¢æµªçº¿ Ë·Ë·Ë·Ë·Ë·Ë·ï¼šæˆ‘è§‰å¾—é‡è¦ï¼Œéå¸¸é‡è¦</li>
  <li>åœ†åœˆ â—¯ï¼šå…³é”®è¯ã€ä¸“ä¸šåç§°</li>
</ul>

<p>è¿™æ ·è¯»è¿‡ä¸€ä¸ªç« èŠ‚ã€ä¸€æœ¬ä¹¦ï¼Œå°±èƒ½è¿›å…¥åˆ°ä¸‹ä¸€ä¸ªæ­¥éª¤ï¼šè®°å½•ã€‚è¿™ä¸ªæ—¶å€™å°±å¯ä»¥ä¸€ä¸€å›é¡¾ä¸Šä¸€æ­¥æ‰€æ ‡è®°å‡ºæ¥çš„éƒ¨åˆ†ï¼Œå‚ç…§ä¸‹é¢çš„æ ¼å¼ï¼Œåœ¨ç¬”è®°æœ¬ä¸Šå†™ä¸‹è¯»è¿‡è¿™æœ¬ä¹¦åçš„è¯»ä¹¦ç¬”è®°ï¼š</p>
<ul>
  <li>âš¬ â€¦æ¥åŸæ–‡æ‘˜æŠ„ã€è¦ç‚¹æ¦‚æ‹¬</li>
  <li>â­‘ â€¦æ¥è¯„è®ºã€æ„Ÿæƒ³</li>
  <li>é‡å¤ä¸Šé¢</li>
</ul>

<p>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ‘˜æŠ„çš„æ—¶å€™ï¼Œå¯ä»¥æ‘˜æŠ„äº›ä»€ä¹ˆå‘¢ï¼Ÿ</p>
<ol>
  <li>èƒ½è®©æˆ‘ä¸»è§‚äº§ç”Ÿå…±é¸£çš„</li>
  <li>ä¸æ˜¯è¯»åè§‰å¾—â€ç†åº”å¦‚æ­¤â€œï¼Œè€Œæ˜¯â€œè¿™ä¹ˆä¸€è¯´ç¡®å®å¦‚æ­¤â€çš„</li>
  <li>èƒ½é¢ è¦†æˆ‘å·²æœ‰çš„æƒ³æ³•ã€åŠ¨æ‘‡æˆ‘è®¤è¯†çš„</li>
  <li>ç­‰ç­‰</li>
</ol>

<p>æ‘˜æŠ„æˆ–è¦ç‚¹æ¦‚æ‹¬å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯åŸä½œè€…çš„æ€æƒ³ï¼Œè€Œåœ¨è¯„è®ºé‡Œï¼Œæˆ‘ä»¬åº”è¯¥å°½é‡å»æŒ–æ˜äº›åŸåˆ›çš„æ€è€ƒã€‚è¿™ä¼šæ˜¯ä¸ªè€—æ—¶é—´è´¹ç²¾åŠ›çš„è¿‡ç¨‹ï¼Œä¸è¿‡åªæœ‰è¯•è¿‡çš„äººæ‰èƒ½çŸ¥é“åˆ°åº•å€¼ä¸å€¼å¾—ã€‚å¦å¤–å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä½œè€…è¿˜æå€¡å°†è·Ÿè¿™æœ¬ä¹¦æœ‰å…³çš„æ—¶é—´ã€ç©ºé—´å°è®°ä¹Ÿä¸€èµ·è´´è¿›ç¬”è®°æœ¬é‡Œï¼Œæ¯”å¦‚è¯´æ–°ä¹¦ä¹°æ¥æ—¶çš„ä¹¦è…°ã€çœ‹é‚£æœ¬ä¹¦æ—¶æ‰€åç«è½¦çš„ç¥¨æ ¹ç­‰ç­‰ã€‚ä»¥åçš„æŸä¸ªæ—¶é—´ï¼Œå†æ¬¡è¯»èµ·ç¬”è®°æœ¬çš„è¿™ä¸€é¡µï¼Œçœ‹é‚£æœ¬ä¹¦æ—¶æ‰€ç»è¿‡çš„é£æ™¯é—»è¿‡çš„èŠ±é¦™ä¹Ÿä¼šè·ƒç„¶çº¸ä¸Šå§ã€‚</p>

<p>å½“ç„¶äº†ï¼Œä¸Šé¢è®²çš„è®°å½•çš„å½¢å¼éƒ½æ˜¯ä½œè€…çš„æ¨èï¼Œæˆ‘ä»¬å¤§å¯ä¸å¿…å±…äºæŸç§å½¢å¼ï¼Œåªéœ€æŒ‰ç…§è‡ªå·±èˆ’æœçš„æ–¹å¼åšæŒè®°ä¸‹å±äºè‡ªå·±çš„è¯»ä¹¦ç¬”è®°å°±å¥½äº†ï¼š</p>
<blockquote>
  <p>è¯´å¥è€ç”Ÿå¸¸è°ˆçš„è¯ï¼Œåªæœ‰æŠŠè¯»ä¹¦ç¬”è®°æ§åˆ¶åœ¨è‡ªå·±èƒ½åŠ›å…è®¸çš„èŒƒå›´å†…ï¼Œæ‰èƒ½é•¿ä¹…åœ°åšæŒä¸‹å»ã€‚æ‰€ä»¥ï¼Œè¦é€‰æ‹©å¯¹è‡ªå·±æ¥è¯´æ¯”è¾ƒæ–¹ä¾¿çš„ç¬”è®°æ–¹æ³•ã€‚</p>
</blockquote>

<p>æˆ‘æƒ³è¿™é“ç†å‡ ä¹é€‚ç”¨äºæ‰€æœ‰éœ€è¦é•¿ä¹…åšæŒçš„äº‹ï¼Œæ¢ç©¶ä¸€é—¨æ·±å¥¥çš„å­¦é—®ã€å­¦ä¹ ä¸€é—¨å¤–è¯­ã€äº¦æˆ–æ˜¯å¥èº«å‡è‚¥ç­‰ç­‰ã€‚æˆ‘å‘ç°äººå¾€å¾€èƒ½è½»æ¾çœ‹åˆ°æ¼«é•¿è¿‡ç¨‹ä¹‹åçš„ä¸€ç§çŠ¶æ€ï¼Œè¿™æˆ–è®¸æ˜¯æˆ‘ä»¬è¿™æ ·é«˜ç­‰ç”Ÿç‰©çš„ç‰¹æ®Šèƒ½åŠ›ï¼›ä½†äººåˆå¾€å¾€å¿ä¸ä½ä¼šå¯¹æœŸå¾…çš„çŠ¶æ€è¿‡äºç€æ€¥ã€‚è¿™çš„ç¡®ä¸æˆ‘ä»¬èº«å¤„çš„ç¤¾ä¼šç¯å¢ƒæœ‰æ‰€å…³ç³»ï¼Œä½†åœ¨æˆ‘ä»¬çš„åŸºå› å½“ä¸­æ˜¯å¦ä¹Ÿæœ‰ç€è¿™ç§æ—¢æœ‰è¿œè§åˆä¼æ±‚è§¦æ‰‹å¯å¾—çš„å›æŠ¥çš„ç§å­å‘¢ï¼Ÿ</p>

<p>æˆ‘åœ¨è¯»è¿™æœ¬ä¹¦çš„æ—¶å€™æ‰€åšçš„è¯»ä¹¦ç¬”è®°å°±æ²¡æœ‰æŒ‰ç…§ä½œè€…æ¨èçš„æ ¼å¼ï¼Œè€Œæ˜¯é‡‡ç”¨äº†è‡ªå·±ä¹ æƒ¯çš„ç±»ä¼¼äºPPTè®¾è®¡çš„é£æ ¼ï¼š
<img src="/assets/2019-11-12/how_to_read.jpg" alt="how_to_read" /></p>

<p>ä¸éš¾çœ‹å‡ºï¼Œç¬”è®°é‡Œçš„ç»“æ„å‡ ä¹åŸå°ä¸åŠ¨åœ°å˜æˆäº†æˆ‘è¿™ç¯‡æ–‡ç« çš„ç»“æ„ï¼Œå†åŠ ä¸Šåœ¨ä¹¦é‡Œç›¸å…³æ ‡è®°å†™ä¸‹çš„è¯„è®ºï¼Œè¿™ç¯‡æ–‡ç« çš„ä¸»è¦å†…å®¹åœ¨æˆ‘åšå®Œè¯»ä¹¦ç¬”è®°çš„åŒæ—¶ä¹Ÿå°±å®Œæˆäº†ã€‚è€Œè¿™ä¹Ÿæ˜¯ä½œè€…æ¨å´‡çš„ï¼Œä»¥è‡ªå·±çš„è¯»ä¹¦ç¬”è®°ä¸ºåŸºç¡€ï¼Œè¿›ä¸€æ­¥å†™å‡ºåŸåˆ›æ–‡ç« ï¼Œåšå±äºè‡ªå·±çš„æ€æƒ³çš„è¾“å‡ºã€‚</p>

<h3 id="é€šè¿‡é‡è¯»ç¬”è®°æé«˜è‡ªæˆ‘">é€šè¿‡é‡è¯»ç¬”è®°æé«˜è‡ªæˆ‘</h3>
<p>è¯»ä¹¦ä½“éªŒçš„æœ€åä¸€æ­¥ï¼Œä¹Ÿæ˜¯æˆ‘ä»æ²¡åšè¿‡çš„ä¸€æ­¥ï¼šé‡è¯»ç¬”è®°ã€‚å°±åƒæœ‰äººä¼šå¶å°”é‡è¯»æ—¥è®°ä¸€æ ·ï¼Œæ—¶å¸¸é‡è¯»è¯»ä¹¦ç¬”è®°èƒ½è®©è‡ªå·±è¯»è¿‡çš„ä¹¦å¥½åƒä¸€ç›´å­˜åœ¨è‡ªå·±ç”Ÿæ´»ä¸­ï¼Œä¸æ–­é…é…¿ï¼Œä¸æ–­è·Ÿè‡ªå·±çš„ç»å†ã€çŸ¥è¯†å‘ç”Ÿæ–°çš„ç¢°æ’ï¼š</p>
<blockquote>
  <p>å¦‚æœæŠŠä¸€æœ¬ä¹¦æ¯”ä½œä¸€ä¸ªâ€œåœºæ‰€â€ï¼Œé‚£ä¹ˆè¯»ä¹¦ç¬”è®°å°±æ˜¯åœ¨è¿™ä¸ªåœºæ‰€æ‹æ‘„çš„ç…§ç‰‡ã€‚åœ¨ä¸åŒæ—¶é—´å»åŒä¸€ä¸ªåœºæ‰€æ‹ç…§ï¼Œæ‹å‡ºæ¥çš„ç…§ç‰‡éƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œè€Œè¿‡ä¸€æ®µæ—¶é—´å†å»çœ‹è¿™äº›ç…§ç‰‡ï¼Œå¯¹é‚£ä¸ªåœºæ‰€çš„å°è±¡ä¹Ÿä¼šå‘ç”Ÿå˜åŒ–ã€‚</p>
</blockquote>

<p>å…³äºå¦‚ä½•é‡è¯»ï¼Œä½œè€…æ¨èï¼š</p>
<ul>
  <li>ç®€å•å›é¡¾ï¼šè¯»ç¬”è®°</li>
  <li>ç»†è‡´å›é¡¾ï¼šè¯»ç¬”è®° + åŸä¹¦æ ‡è®°</li>
  <li>ç»å…¸é‡æ¸©ï¼šè¯»ç¬”è®° + åŸä¹¦</li>
</ul>

<p>è¿™ä¹ˆçœ‹ï¼Œæˆ‘ç¡®å®ä¸€ä¸ªå›é¡¾éƒ½æ²¡åšè¿‡ğŸ˜‚ã€‚ä¸€å¼€å§‹è¯»è¿™æœ¬ä¹¦æ˜¯å› ä¸ºä¹°äº†æ–°çš„ç¬”è®°æœ¬ï¼Œæˆ‘è€æ˜¯ä¹°æ–°ç¬”è®°æœ¬ï¼Œæƒ³ç€è¦å†™ç‚¹ä»€ä¹ˆæ–‡å­—ï¼Œæœ€åéƒ½æ²¦ä¸ºå¹³æ—¶å·¥ä½œç”¨çš„è‰ç¨¿çº¸ï¼ˆä¹Ÿæ˜¯å¾ˆé‡è¦å•¦ï¼‰ã€‚çœ‹äº†è¿™æœ¬ä¹¦çš„è¯„è®ºè§‰å¾—å¯èƒ½ä¼šå¸®æˆ‘ç»“æŸè¿™ä¸ªå¾ªç¯ï¼Œç›®å‰çœ‹æ¥å¾ˆæœ‰å¸Œæœ›ã€‚è¯»ä¹‹å‰ï¼Œå¦‚ä½•å†™è¯»ä¹¦ç¬”è®°æ˜¯æˆ‘æœ€æ„Ÿå…´è¶£çš„éƒ¨åˆ†ï¼Œä¸è¿‡è¯»å®Œå‘ç°ï¼Œä»¥éšæƒ³ç¬”è®°åˆ°ç¬”è®°å›é¡¾çš„ä¸€æ•´ä¸ªè¯»ä¹¦ä½“éªŒæ¥ç†è§£è¯»ä¹¦è¿™äº‹å„¿ï¼Œæ‰æ˜¯å¥¥é‡å®£ä¹‹è¿™æœ¬ä¹¦ç»™æˆ‘æœ€å¤§çš„æ”¶è·å§ã€‚</p>
 -->
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

    </div>

  </body>
</html>
