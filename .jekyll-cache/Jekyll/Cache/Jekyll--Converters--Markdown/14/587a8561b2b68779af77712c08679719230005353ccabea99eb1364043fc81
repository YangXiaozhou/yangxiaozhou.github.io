I",<p>In this article, I’ll walk you through the COVID-19 convolutional neural network (CNN) classifier that we’ve built as an entry to the 2020 INFORMS QSR Data <a href="https://connect.informs.org/HigherLogic/System/DownloadDocumentFile.ashx?DocumentFileKey=f404f7b8-fcd6-75d5-f7a7-d262eab132e7">Challenge</a>. This article focuses on the <strong>implementation</strong> of an end-to-end CNN image classifier using <code class="highlighter-rouge">tensorflow.keras</code>. If you are not familiar with CNN, or would like a refresher on the key features of CNNs, I highly recommend reading <a href="http://yangxiaozhou.github.io/data/2020-09-24-intro-to-cnn.html">Introduction to convolutional neural network</a> first.</p>

<ul id="markdown-toc">
  <li><a href="#whats-the-challenge" id="markdown-toc-whats-the-challenge">What’s the challenge?</a></li>
  <li><a href="#proprocessing" id="markdown-toc-proprocessing">Proprocessing</a>    <ul>
      <li><a href="#classifier-via-transfer-learning" id="markdown-toc-classifier-via-transfer-learning">Classifier via transfer learning</a></li>
    </ul>
  </li>
  <li><a href="#where-do-we-go-from-here" id="markdown-toc-where-do-we-go-from-here">Where do we go from here?</a></li>
</ul>

<hr />

<p>The COVID-19 pandemic has changed lives around the world. This is the current situation as of 2020/09/24 according to <a href="https://covid19.who.int/">WHO</a>. 
<img src="/assets/cnn-covid-19/covid-19-pandemic.png" alt="current situation" /></p>

<h1 id="whats-the-challenge">What’s the challenge?</h1>

<p><strong>Computed tomography (CT) scans</strong> have been used for screening and diagnosing COVID-19, especially in areas where swab test resources are severely lacking. The goal of the data challenge is to diagnose COVID-19 using the chest CT scans.</p>

<p>Therefore, the challenge is to come up with a <strong>classification model</strong> that classify patients to COVID or NonCOVID based on their chest CT scans, <strong>as accurately as possible</strong>.</p>

<h3 id="whats-provided">What’s provided?</h3>

<ul>
  <li>Training data set
    <ul>
      <li>251 COVID-19 CT images</li>
      <li>292 non-COVID-19 CT images</li>
    </ul>
  </li>
  <li>Meta-information
    <ul>
      <li>e.g., patient information, severity, image caption</li>
    </ul>
  </li>
</ul>

<p>All data are taken from a <a href="https://github.com/UCSD-AI4H/COVID-CT">public data set</a>.</p>

<h1 id="proprocessing">Proprocessing</h1>

<p>Let’s have a look at some NonCOVID and COVID CT scans. It’s important to note that the challenge is to distinguish between COVID and NonCOVID CT scans, rather than COVID and Normal scans. In fact, it is obvious that the NonCOVID scans show different degree of abnormal patterns. This is because the similar patterns can develop in COVID-19 patients as well as other pneumonia patients. 
<img src="/assets/cnn-covid-19/first_look.png" alt="first_look" /></p>

<h3 id="set-up-data-for-training">Set up data for training</h3>
<p>We reserve 20% of the data for validation. Since some consecutive images come from the same patient, they tend to be similar to each other.  That is, many of our data are <strong>not independent</strong>. To prevent data leakage (information of training data spills over to validation data), we keep the original image sequence and hold out the last 20% as the validation set.</p>

<p>After the splitting, we have two pairs of data:</p>
<ol>
  <li><code class="highlighter-rouge">X_train</code>, <code class="highlighter-rouge">y_train</code></li>
  <li><code class="highlighter-rouge">X_val</code>, <code class="highlighter-rouge">y_val</code></li>
</ol>

<p>X is a list of CT scans, and y is a list of binary labels (0 for NonCOVID, 1 for COVID).</p>

<h3 id="create-tfdatadataset-object">Create <code class="highlighter-rouge">tf.data.Dataset</code> object</h3>

<p>Data science workflow unique to <code class="highlighter-rouge">tensorflow</code> is the usage of <code class="highlighter-rouge">Dataset</code> object. The <code class="highlighter-rouge">tf.data.Dataset</code> API supports writing descriptive and efficient input pipelines. Essentially, it is a tensorflow data structure that greatly simplifies some essential operations, for example, preprocessing, shuffling and training. You can read more about it <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle">here</a>.</p>

<p>We create two <code class="highlighter-rouge">tf.data.Dataset</code> objects, one for training and the other for validation. We also define a wrapper <code class="highlighter-rouge">resize_and_shuffle</code> function where</p>
<ol>
  <li>create a <code class="highlighter-rouge">Dataset</code> object from a (<code class="highlighter-rouge">X, y</code>) pair,</li>
  <li>resize each image to a standard size,</li>
  <li>shuffle and split the data into batches for training later.</li>
</ol>

<h2 id="classifier-via-transfer-learning">Classifier via transfer learning</h2>
<h3 id="pre-processing">Pre-processing</h3>
<h3 id="transfer-learning">Transfer learning</h3>

<h1 id="where-do-we-go-from-here">Where do we go from here?</h1>

:ET