I"ù*<p><em>Tagline</em></p>

<!-- ![mda](/assets/2019-10-02/mda.png) -->

<ul id="markdown-toc">
  <li><a href="#key-takeaways" id="markdown-toc-key-takeaways">Key takeaways</a></li>
  <li><a href="#introduction-to-convolutional-neural-network" id="markdown-toc-introduction-to-convolutional-neural-network">Introduction to convolutional neural network</a>    <ul>
      <li><a href="#deep-neural-network" id="markdown-toc-deep-neural-network">Deep neural network</a></li>
      <li><a href="#convolutional-neural-network" id="markdown-toc-convolutional-neural-network">Convolutional neural network</a></li>
    </ul>
  </li>
  <li><a href="#covid-19-classifier-using-cnn" id="markdown-toc-covid-19-classifier-using-cnn">COVID-19 classifier using CNN</a>    <ul>
      <li><a href="#informs-data-challenge" id="markdown-toc-informs-data-challenge">INFORMS data challenge</a></li>
      <li><a href="#classifier-via-transfer-learning" id="markdown-toc-classifier-via-transfer-learning">Classifier via transfer learning</a></li>
    </ul>
  </li>
  <li><a href="#where-do-we-go-from-here" id="markdown-toc-where-do-we-go-from-here">Where do we go from here?</a></li>
</ul>
<hr />

<h1 id="key-takeaways">Key takeaways</h1>
<p>1.
2.
3.</p>

<h1 id="introduction-to-convolutional-neural-network">Introduction to convolutional neural network</h1>

<p>To get everyone on the same page, I am going to introduce very briefly what are <strong>deep neural networks</strong> (DNNs) and <strong>convolutional neural networks</strong> (CNNs). At the end of this section, you can gain an intuitive understanding of the motivation behind CNN and the key components that define a CNN.</p>

<p>If you are already familiar with DNNs, you can skip to <a href="#Convolutional neural network">Convolutional neural network</a> or <a href="#COVID-19 classifier using CNN">COVID-19 classifier using CNN</a>.</p>

<h2 id="deep-neural-network">Deep neural network</h2>

<p>Before diving into neural networks, let‚Äôs first see the machine learning big picture:</p>
<blockquote>
  <p><strong>Machine learning</strong> (ML) is the study of computer algorithms that improve automatically through experience. ‚Äì Wikipedia</p>
</blockquote>

<p>Looking at the problems that ML tries to solve, ML is often sliced into</p>
<ul>
  <li>Supervised learning: predicting a label, e.g. classification, or a continuous variable;</li>
  <li>Unsupervised learning: pattern recognition for unlabeled data, e.g., clustering;</li>
  <li>Reinforcement learning: algorithms learn the best way to ‚Äúbehave‚Äù, e.g. AlphaGo, self-driving cars.</li>
</ul>

<p>Deep learning, among others, is a powerful form of machine learning that has garnered much attention for its successes in computer vision (e.g. image recognition), natural language processing, and beyond. Neural network is originally inspired by information processing and communication nodes in biological systems. By design, input data is passed through layers of the network, which contain a number of nodes, analogous to ‚Äúneurons‚Äù. The system then outputs a certain representation of the information. DNN is probably the most well-known network for deep learning and it can be trained to learn the features of the data very well.</p>

<p><img src="/assets/cnn-covid-19/deep-nn.jpg" alt="Deep neural network" />Image <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347705/">credit</a>.</p>

<p>Roughly speaking, there are two important operations that make a neural network.</p>
<ol>
  <li><strong>Forward propagation</strong></li>
  <li><strong>Backpropagation</strong></li>
</ol>

<h3 id="forward-propagation">Forward propagation</h3>
<p>This is the <strong>prediction</strong> step. The network reads the input data, computes its values across the network and gives a final output value.</p>

<p>But how does the network computes an output value? Let‚Äôs see what happens in a single layer network when it does one prediction. It takes in inputs as a vector of numbers. Each node in the layers has its own weight. When the input value is passed through the layer, DNN computes its weighted sum. This is usually followed by a (usually nonlinear) activation function where the weighted sum is ‚Äúactivated‚Äù through a (usually nonlinear) activation function, e.g. step function.</p>

<p><img src="/assets/cnn-covid-19/perceptron.jpg" alt="perceptron" /> Image <a href="https://deepai.org/machine-learning-glossary-and-terms/perceptron">credit</a>.</p>

<p>If you know a bit about algebra, this is what the operation is doing:</p>
<ul>
  <li>$y = f(\mathbf{w}\cdot \mathbf{x} + b) $</li>
</ul>

<p>where $\mathbf{w}\cdot \mathbf{x} + b$ is the weighted sum, $f(\cdot)$ is the activation function, and $y$ is the output.</p>

<p>Now, in a deeper neural network, the procedure is essentially the same. The input ‚Äì&gt; weighted sum ‚Äì&gt; activation process is done for each layer.</p>

<p><img src="../img/mlp.png" alt="title" /></p>

<p>Image <a href="https://www.cs.purdue.edu/homes/ribeirob/courses/Spring2020/lectures/03/MLP_and_backprop.html">credit</a>.</p>

<h3 id="backpropagation">Backpropagation</h3>

<ul>
  <li>By comparing the predictions and the ground truth values (loss), the network adjusts its parameters so that the performance is improved.</li>
  <li>This is the <strong>training</strong> step.</li>
</ul>

<p>How does the network adjust the weights through training?</p>

<p>This is done through an operation called <strong>backpropagation</strong>, or backprop. The network takes the loss and recursively calculates the slope of the loss function with respect to each network parameter. Calculating these slopes requires the usage of chain rule from calculus, you can read more about it <a href="https://sebastianraschka.com/faq/docs/backprop-arbitrary.html">here</a>.</p>

<p>An optimization algorithm is then used to update network parameters using the gradient information until the performance cannot be improved anymore. One commonly used optimizer is stochastic gradient descent.</p>

<p>One analogy often used to explain gradient-based optimization is hiking:</p>
<ul>
  <li>Training the network so that its loss is minimized is like trying to get down to the lowest point on the ground from a mountain.</li>
  <li>Backprop operation finding the loss function gradients is like finding the path on your way down.</li>
  <li>Optimization algorithm is the step where you actually take the path and eventually reach the lowest point.</li>
</ul>

<p><img src="../img/gradient-descent.png" alt="title" />
Image <a href="https://www.datasciencecentral.com/profiles/blogs/alternatives-to-the-gradient-descent-algorithm">credit</a>.</p>

<p>So now you know that DNN</p>
<ul>
  <li>is a powerful <strong>machine learning</strong> technique</li>
  <li>can be used to tackle <strong>supervised</strong>, <strong>unsupervised</strong> and <strong>reinforcement learning</strong> problems</li>
  <li>consists of forward propagation (<strong>input to output</strong>) and backpropagation (<strong>error to parameter update</strong>)</li>
</ul>

<p>We are ready to talk about CNN!</p>

<h2 id="convolutional-neural-network">Convolutional neural network</h2>

<p>Ordinary neural networks that we‚Äôve talked about above expect input data to be a <strong>vector of numbers</strong>:
$\mathbf{x} = [x_1, x_2, x_3, \dots]$</p>

<p>What if we want to train an <strong>image classifier</strong>, i.e. use image as the input?</p>

<h3 id="motivation">Motivation</h3>

<p>Digital image basics:</p>
<ul>
  <li>An image is a <strong>collection of pixels</strong>. For example, a 32-by-32 image has $32 \times 32 = 1024$ pixels.</li>
  <li>Each pixel is an <strong>intensity represented by a number</strong> in the range $[0, 255]$, $0$ is black and $255$ is white.</li>
  <li>Color images have three dimensions: <strong>[width, height, depth]</strong> where depth is usually 3.</li>
  <li>Why is depth 3? That‚Äôs because it encodes the intensity of [<strong>R</strong>ed, <strong>G</strong>reen, <strong>B</strong>lue], i.e. RGB values.</li>
</ul>

<p>Therefore, to a computer program, this black and white Lincoln image is just a matrix of integers. 
<img src="../img/image_pixel.png" alt="image" />
Image <a href="https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html">credit</a></p>

<p>Since a digital image can be represented as a 2D grid of pixel values, we could stretch out the grid, make it into a vector of numbers and feed it into a neural network.</p>

<p>However, there are two major limitations to this approach.</p>

<ol>
  <li><strong>It does not scale well to bigger images.</strong>
    <ul>
      <li>While it is still manageable for an input with $32\times32 = 1024$ dimensions, most real-life images are bigger than this.</li>
      <li>For example, a color image of size 320x320x3 would translate to an input with dimension <strong>307200</strong>!</li>
    </ul>
  </li>
  <li><strong>It does not consider the properties of an image.</strong>
    <ul>
      <li><em>Locality</em>: Nearby pixels are usually strongly correlated (e.g., see the face outline above). Stretching it out breaks the pattern.</li>
      <li><em>Translation invariance</em>: Meaningful features could occur anywhere on an image, e.g., see the flying bird. 
<img src="../img/flying-bird.png" alt="bird" /></li>
    </ul>
  </li>
</ol>

<p>Image <a href="https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf">credit</a></p>

<h3 id="convolution">Convolution</h3>

<p>On the other hand, CNN is designed to scale well with images and take advantage of these unique properties.</p>

<ol>
  <li><strong>Weight sharing</strong>: All local parts of the image are processed with the same weights so that identical patterns could be detected at many locations, e.g., horizontal edges, curves and etc.</li>
  <li><strong>Hierarchy of features</strong>: Lower-level patterns are composed to form higher-level ones, e.g., edges ‚Äì&gt; contour ‚Äì&gt; face outline</li>
</ol>

<p>This is done through the operation of <strong>convolution</strong>:</p>

<ol>
  <li>Define a filter: a 2D weight matrix of a certain size.</li>
  <li>Convolve the whole image with the filter: multiply each pixel under the filter with the weight.</li>
  <li>Convolution output forms a new image: a feature map.</li>
  <li>By using multiple filters (each with a different weight matrix), different features can be captures.</li>
</ol>

<h1 id="covid-19-classifier-using-cnn">COVID-19 classifier using CNN</h1>

<h2 id="informs-data-challenge">INFORMS data challenge</h2>
<h2 id="classifier-via-transfer-learning">Classifier via transfer learning</h2>
<h3 id="pre-processing">Pre-processing</h3>
<h3 id="transfer-learning">Transfer learning</h3>

<h1 id="where-do-we-go-from-here">Where do we go from here?</h1>

<hr />
<h2 class="no_toc" id="references">References</h2>

:ET