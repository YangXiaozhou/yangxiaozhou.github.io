I"Œ<p>By now, youâ€™ve probably seen a few, if not dozens, of articles on how deep learning could help detect COVID-19[refs]. In particular, convolutional neural networks (CNNs) have been studied as a faster and cheaper alternative to the gold-standard PCR test by just analyzing the patientâ€™s computed tomography (CT) scan. Itâ€™s not surprising since CNN is excellent at image recognition; Many places have CT scanners rather than COVID-19 testing kits (at least initially)[refs].</p>

<p>But, despite its success on image recognition tasks such as the ImageNet challenge, can CNN really help doctors detect COVID-19? If it can, how accurately can it do so? Itâ€™s well known that CT scans are sensitive but not specific to COVID-19[refs]. That is, COVID-19 almost always produces abnormal lung patterns visible from CT scans. However, other pneumonia can produce the same abnormal patterns. Can the powerful and sometimes magical CNN tackle this ambiguity issue?</p>

<p>We had a chance to answer these questions ourselves (with my colleague <a href="">Yuchen</a> and advisor <a href="">A/P Chen</a>). Iâ€™ll walk you through a COVID-19 classifier that weâ€™ve built as an entry to the 2020 INFORMS QSR Data <a href="https://connect.informs.org/HigherLogic/System/DownloadDocumentFile.ashx?DocumentFileKey=f404f7b8-fcd6-75d5-f7a7-d262eab132e7">Challenge</a>. If you are not familiar with CNN, or would like a refresher on the key features of CNNs, I highly recommend reading <a href="https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html">Convolutional Neural Network: How is it different from the other networks?</a> first. You can get all the code and data from this Github repo.</p>

<h3 id="key-takeaways">Key takeaways</h3>
<ol>
  <li>Transfer learning using pre-trained CNN can achieve really strong baseline performance on COVID-19 classification (85% accuracy).</li>
  <li>However, domain expertise is required to elevate the performance of the CNN (or other ML methods).</li>
</ol>

<hr />
<h1 id="whats-the-challenge">Whatâ€™s the challenge?</h1>

<p>The COVID-19 pandemic has changed lives around the world. This is the current situation as of 2020/09/26 according to <a href="https://covid19.who.int/">WHO</a>. 
<img src="/assets/cnn-covid-19/covid-19-pandemic.png" alt="current situation" /></p>

<p>CT scans have been used for screening and diagnosing COVID-19, especially in areas where swab test resources are severely lacking. The goal of this data challenge is to diagnose COVID-19 using the chest CT scans. Therefore, we need to build a <strong>classification model</strong> that can classify patients to COVID or NonCOVID based on their chest CT scans, <strong>as accurately as possible</strong>.</p>

<h2 id="whats-provided">Whatâ€™s provided?</h2>
<p>Relatively even number of COVID and NonCOVID images are provided to train the model. While meta-information of these images are also provided, they will not be provided during testing.</p>

<ul>
  <li>Training data set
    <ul>
      <li>251 COVID-19 CT images</li>
      <li>292 non-COVID-19 CT images</li>
    </ul>
  </li>
  <li>Meta-information
    <ul>
      <li>e.g., patient information, severity, image caption</li>
    </ul>
  </li>
</ul>

<p>All data are taken from a <a href="https://github.com/UCSD-AI4H/COVID-CT">public data set</a>.</p>

<h1 id="model-performance">Model performance</h1>
<p>Letâ€™s first take a look at the end result, shall we?</p>

<p>The trained model is evaluated with an independent set of test data. Here you can see the confusion matrix. The overall accuracy is about 85% with a slightly better sensitivity than specificity, i.e., true positive rate &gt; true negative rate. 
<img src="/assets/cnn-covid-19/confusion_matrix.png" alt="confusion" /></p>

<h1 id="implementation">Implementation</h1>
<p>Here are some of the provided NonCOVID and COVID CT scans. Itâ€™s important to note that the challenge is to distinguish between COVID and NonCOVID CT scans, rather than COVID and Normal scans. In fact, there may be some NonCOVID CT scans that belong to other pneumonia patients. 
<img src="/assets/cnn-covid-19/first_look.png" alt="first_look" /></p>

<h2 id="set-up-data-for-training">Set up data for training</h2>
<p>We reserve 20% of the data for validation. Since some consecutive images come from the same patient, they tend to be similar to each other.  That is, many of our data are <strong>not independent</strong>. To prevent data leakage (information of training data spills over to validation data), we keep the original image sequence and hold out the last 20% as the validation set.</p>

<p>After the splitting, we have two pairs of data:</p>
<ol>
  <li><code class="highlighter-rouge">X_train</code>, <code class="highlighter-rouge">y_train</code></li>
  <li><code class="highlighter-rouge">X_val</code>, <code class="highlighter-rouge">y_val</code></li>
</ol>

<p>X is a list of CT scans, and y is a list of binary labels (0 for NonCOVID, 1 for COVID).</p>

<h3 id="create-tfdatadataset-object">Create <code class="highlighter-rouge">tf.data.Dataset</code> object</h3>

<p>Data science workflow unique to <code class="highlighter-rouge">tensorflow</code> is the usage of <code class="highlighter-rouge">Dataset</code> object. The <code class="highlighter-rouge">tf.data.Dataset</code> API supports writing descriptive and efficient input pipelines. Essentially, it is a tensorflow data structure that greatly simplifies some essential operations, for example, preprocessing, shuffling and training. You can read more about it <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle">here</a>.</p>

<p>We create two <code class="highlighter-rouge">tf.data.Dataset</code> objects, one for training and the other for validation. We also define a wrapper <code class="highlighter-rouge">resize_and_shuffle</code> function where we</p>
<ol>
  <li>create a <code class="highlighter-rouge">Dataset</code> object from a (<code class="highlighter-rouge">X, y</code>) pair,</li>
  <li>resize each image to a standard size,</li>
  <li>shuffle and split the data into batches for CNN training later.</li>
</ol>

<h1 id="what-have-we-learned">What have we learned?</h1>

<h1 id="where-do-we-go-from-here">Where do we go from here?</h1>

:ET