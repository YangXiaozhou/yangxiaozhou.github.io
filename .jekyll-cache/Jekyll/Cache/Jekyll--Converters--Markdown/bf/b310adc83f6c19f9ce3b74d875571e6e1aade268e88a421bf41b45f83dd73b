I"<p>2020.02.06 - 安排自己的PhD训练
让自己的PhD training变得structured, how?
Schedule around deep work:</p>
<ol>
  <li>Research work</li>
  <li>Academic training</li>
  <li>Professional development</li>
</ol>

<p>今天读Aeon的一篇文章：<a href="https://aeon.co/ideas/algorithms-associating-appearance-and-criminality-have-a-dark-past?utm_source=Aeon+Newsletter&amp;utm_campaign=f7c118f081-EMAIL_CAMPAIGN_2020_05_11_01_52&amp;utm_medium=email&amp;utm_term=0_411a82e59d-f7c118f081-69607277">Algorithms associating appearance and criminality have a dark past</a>，讲现在的一些机器学习研究如何用算法通过人脸来判断这人犯罪的几率。文中讲到这种从人外表提取预见性的特征的尝试，并不是我们历史上的第一次，19世纪的意大利犯罪学家Cesare Lombroso认为罪犯的脸部有独特的样貌：突出的前额、鹰型鼻梁，而18世纪的Francis Galton则尝试回答一个更广泛的问题：人的外表跟他或她的健康状况、犯罪倾向、智力等等有关系吗？或者说，人的基因是否决定了健康、行为、智力和竞争力？</p>

<p>Francis Galton?
我隐约记得这名字在我老板的一门预测的统计课上听到过。仔细一想，对，在讲到线性回归的部分时，老板专门用了一页的篇幅介绍他。Sir Francis Galton，姓Galton，名Francis，但当提到他时，出于礼仪，你得加个Sir，因为他在1909年被英国女王授予了骑士爵位。为什么在讲线性回归的时候要介绍他呢？因为他作为第一人，描述了这样一种现象：平均身高很高的父母，往往会有身高更接近普通的孩子；而平均身高很低的父母的孩子，通常也能长到更接近普通人的身高。下图是<a href="https://www.ams.org/journals/bull/2013-50-01/S0273-0979-2012-01374-5/S0273-0979-2012-01374-5.pdf">Bradley Efron</a>根据Galton当时收集到的父母和孩子的身高数据重新制的图，完美地展现了我们现在所知道的Bivariate normal distribution。
<img src="/assets/month-journal/regression_to_mean.png" alt="regression_to_mean" />
这种现象，他称为”regression towards mediocrity”，现在通常叫做regression toward the mean。同样的现象，我们在生活中很多地方都很观察到：连续投中三个三分球的朋友，下个球往往“容易”失手；我上周做的<a href="https://yangxiaozhou.github.io/learning/2019/01/01/recipe.html#%E6%B2%B9%E6%B3%BC%E7%8C%AA%E6%89%8B">油泼猪手</a>各种调料拿捏得很好，味道超棒，这周再做一次，大概率味道会比较普通🤷‍♂️。符合这原则的现象，他们有一个共通点：他们的结果往往是由某些决定性因素和随机性因素共同决定的，而随机因素的影响往往符合以0为中心的正态分布（时好时坏）。比如说，三分球进或不进，有投手能力的影响也有运气的成分；我做的某道菜的味道，下厨能力会影响，我的专心程度、手抖程度以及心情等几乎随机的因素也会影响。也就是说，假设某一天我超级走运，做出了迄今为止最好吃的一道菜，这种事件发生的概率是很小的，等于得到正态分布上的极大值（或极小值）的概率。下一次做，大概率我只会正常发挥</p>

:ET